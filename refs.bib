
@misc{orthrus-lexicon_orthrus_2022,
	title = {Orthrus {Toxic} {Dictionary} implementation},
	url = {https://github.com/Orthrus-Lexicon/Toxic},
	abstract = {A dictionary of toxic words},
	urldate = {2023-01-07},
	author = {Orthrus-Lexicon},
	month = sep,
	year = {2022},
	note = {original-date: 2021-02-14T15:47:49Z},
}

@article{proctor_editors_2018,
	title = {Editors’ {Introduction}: {On} toxic fan practices and the new culture wars},
	volume = {15},
	language = {en},
	number = {1},
	author = {Proctor, William and Kies, Bridget},
	year = {2018},
	file = {Proctor and Kies - 2018 - Editors’ Introduction On toxic fan practices and .pdf:/Users/I516998/Zotero/storage/RXUKCSA5/Proctor and Kies - 2018 - Editors’ Introduction On toxic fan practices and .pdf:application/pdf},
}

@misc{toxic_fandom,
	title = {What {Is} {Toxic} {Fandom}?},
	url = {https://www.verywellmind.com/what-is-toxic-fandom-5214499},
	abstract = {Toxic fandom encompasses a range of negative, abusive, and antisocial behaviors by fans, usually via social media. Learn about fandom and toxic fans.},
	language = {en},
	urldate = {2023-01-07},
	journal = {Verywell Mind},
	note = {Section: Verywell},
	file = {Snapshot:/Users/I516998/Zotero/storage/QLI6KXYU/what-is-toxic-fandom-5214499.html:text/html},
}

@misc{f1_drivers_addressing_toxic_fans,
	title = {3 times {F1} drivers addressed toxic fan behavior},
	url = {https://www.sportskeeda.com/f1/3-times-f1-drivers-addressed-toxic-fan-behavior},
	urldate = {2023-01-07},
	file = {3 times F1 drivers addressed toxic fan behavior:/Users/I516998/Zotero/storage/63GT6CDF/3-times-f1-drivers-addressed-toxic-fan-behavior.html:text/html},
}

@article{arouh_toxic_2020,
	title = {Toxic {Fans}: {Distinctions} and {Ambivalence}},
	copyright = {Copyright (c) 2020 Melenia Arouh},
	issn = {2585-3538},
	shorttitle = {Toxic {Fans}},
	url = {https://ejournals.lib.auth.gr/ExCentric/article/view/7917},
	doi = {10.26262/exna.v0i4.7917},
	abstract = {Participation in online fandoms of popular culture has become today a mainstream activity, receiving much scholarly and industry attention. This attention has been both positive and negative, at certain times praising the enthusiasm and innovation of fans, while at other times criticizing toxic practices deemed disruptive and destructive. This paper reviews what is generally termed as “toxic fans,” in an effort to explicate its meaning as well as its underlying moral framing. Specifically, the etymology of the word toxic is considered so as to explain how it is used in current discourse about online fan culture. Following this discussion, it is argued that the nature of fan practices should be closely studied in relation to prevalent attitudes in contemporary society that are defined by fear and a certain “othering” of the online fanatic. Finally, the ambivalent nature of the word toxic is discussed in relation to the antagonism usually observed in producer/fan relations as these are conducted in online spaces.},
	language = {en},
	number = {4},
	urldate = {2023-01-07},
	journal = {Ex-centric Narratives: Journal of Anglophone Literature, Culture and Media},
	author = {Arouh, Melenia},
	month = dec,
	year = {2020},
	note = {Number: 4},
	pages = {67--82},
	file = {Full Text PDF:/Users/I516998/Zotero/storage/NGH3HRBM/Arouh - 2020 - Toxic Fans Distinctions and Ambivalence.pdf:application/pdf},
}

@article{van_der_vegt_grievance_2021,
	title = {The {Grievance} {Dictionary}: {Understanding} threatening language use},
	volume = {53},
	issn = {1554-3528},
	shorttitle = {The {Grievance} {Dictionary}},
	url = {https://link.springer.com/10.3758/s13428-021-01536-2},
	doi = {10.3758/s13428-021-01536-2},
	abstract = {This paper introduces the Grievance Dictionary, a psycholinguistic dictionary that can be used to automatically understand language use in the context of grievance-fueled violence threat assessment. We describe the development of the dictionary, which was informed by suggestions from experienced threat assessment practitioners. These suggestions and subsequent human and computational word list generation resulted in a dictionary of 20,502 words annotated by 2318 participants. The dictionary was validated by applying it to texts written by violent and non-violent individuals, showing strong evidence for a difference between populations in several dictionary categories. Further classification tasks showed promising performance, but future improvements are still needed. Finally, we provide instructions and suggestions for the use of the Grievance Dictionary by security professionals and (violence) researchers.},
	language = {en},
	number = {5},
	urldate = {2023-01-07},
	journal = {Behavior Research Methods},
	author = {van der Vegt, Isabelle and Mozes, Maximilian and Kleinberg, Bennett and Gill, Paul},
	month = oct,
	year = {2021},
	pages = {2105--2119},
	file = {van der Vegt et al. - 2021 - The Grievance Dictionary Understanding threatenin.pdf:/Users/I516998/Zotero/storage/32VJHLN6/van der Vegt et al. - 2021 - The Grievance Dictionary Understanding threatenin.pdf:application/pdf},
}

@misc{ethnic_slurs,
	title = {List of ethnic slurs},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=List_of_ethnic_slurs&oldid=1132041045},
	abstract = {The following is a list of ethnic slurs or ethnophaulisms or ethnic epithets that are, or have been, used as insinuations or allegations about members of a given ethnicity or racial group or to refer to them in a derogatory, pejorative, or otherwise insulting manner.
Some of the terms listed below (such as "gringo", "yank", etc.) can be used in casual speech without any intention of causing offense. The connotation of a term and prevalence of its use as a pejorative or neutral descriptor varies over time and by geography.
For the purposes of this list, an ethnic slur is a term designed to insult others on the basis of race, ethnicity, or nationality. Each term is listed followed by its country or region of usage, a definition, and a reference to that term.
Ethnic slurs may also be produced as a racial epithet by combining a general-purpose insult with the name of ethnicity, such as "dirty Jew", "Russian pig", etc. Other common insulting modifiers include "dog", "filthy", etc. However, such terms are not included in this list.},
	language = {en},
	urldate = {2023-01-07},
	journal = {Wikipedia},
	month = jan,
	year = {2023},
	note = {Page Version ID: 1132041045},
	file = {Snapshot:/Users/I516998/Zotero/storage/MATAY5SA/List_of_ethnic_slurs.html:text/html},
}


@misc{hate_speech_classifier,
	title = {Deep {Learning} {Models} for {Multilingual} {Hate} {Speech} {Detection}},
	url = {http://arxiv.org/abs/2004.06465},
	doi = {10.48550/arXiv.2004.06465},
	abstract = {Hate speech detection is a challenging problem with most of the datasets available in only one language: English. In this paper, we conduct a large scale analysis of multilingual hate speech in 9 languages from 16 different sources. We observe that in low resource setting, simple models such as LASER embedding with logistic regression performs the best, while in high resource setting BERT based models perform better. In case of zero-shot classification, languages such as Italian and Portuguese achieve good results. Our proposed framework could be used as an efficient solution for low-resource languages. These models could also act as good baselines for future multilingual hate speech detection tasks. We have made our code and experimental settings public for other researchers at https://github.com/punyajoy/DE-LIMIT.},
	urldate = {2023-01-09},
	publisher = {arXiv},
	author = {Aluru, Sai Saketh and Mathew, Binny and Saha, Punyajoy and Mukherjee, Animesh},
	month = dec,
	year = {2020},
	note = {arXiv:2004.06465 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Social and Information Networks},
	annote = {Comment: 16 pages, Accepted at ECML-PKDD 2020},
	file = {arXiv Fulltext PDF:/Users/I516998/Zotero/storage/4LFQE267/Aluru et al. - 2020 - Deep Learning Models for Multilingual Hate Speech .pdf:application/pdf;arXiv.org Snapshot:/Users/I516998/Zotero/storage/AQRZKRUD/2004.html:text/html},
}

@misc{tweet_sentiment_classifier,
	title = {{TweetEval}: {Unified} {Benchmark} and {Comparative} {Evaluation} for {Tweet} {Classification}},
	shorttitle = {{TweetEval}},
	url = {http://arxiv.org/abs/2010.12421},
	abstract = {The experimental landscape in natural language processing for social media is too fragmented. Each year, new shared tasks and datasets are proposed, ranging from classics like sentiment analysis to irony detection or emoji prediction. Therefore, it is unclear what the current state of the art is, as there is no standardized evaluation protocol, neither a strong set of baselines trained on such domain-specific data. In this paper, we propose a new evaluation framework (TweetEval) consisting of seven heterogeneous Twitter-specific classification tasks. We also provide a strong set of baselines as starting point, and compare different language modeling pre-training strategies. Our initial experiments show the effectiveness of starting off with existing pre-trained generic language models, and continue training them on Twitter corpora.},
	urldate = {2023-01-09},
	publisher = {arXiv},
	author = {Barbieri, Francesco and Camacho-Collados, Jose and Neves, Leonardo and Espinosa-Anke, Luis},
	month = oct,
	year = {2020},
	note = {arXiv:2010.12421 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Social and Information Networks},
	annote = {Comment: Findings of EMNLP 2020. TweetEval benchmark available at https://github.com/cardiffnlp/tweeteval},
	file = {arXiv Fulltext PDF:/Users/I516998/Zotero/storage/Y2BYP35N/Barbieri et al. - 2020 - TweetEval Unified Benchmark and Comparative Evalu.pdf:application/pdf;arXiv.org Snapshot:/Users/I516998/Zotero/storage/663Q8R8A/2010.html:text/html},
}


@misc {distilbert_sentiment,
	author       = { {HF Canonical Model Maintainers} },
	title        = { distilbert-base-uncased-finetuned-sst-2-english (Revision bfdd146) },
	year         = 2022,
	url          = { https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english },
	doi          = { 10.57967/hf/0181 },
	publisher    = { Hugging Face }
}



@misc{about_f1,
	title = {About {F1} {\textbar} {Formula} {One} {World} {Championship} {Limited}},
	url = {https://corp.formula1.com/about-f1/},
	abstract = {Formula 1® racing began in 1950 and is the world’s most prestigious motor racing competition, as well as the world’s most popular annual sporting series: Th ...},
	language = {en-US},
	urldate = {2023-01-09},
	author = {Lowrey, Trevin},
	month = feb,
	year = {2019},
	file = {Snapshot:/Users/I516998/Zotero/storage/9MD8EDPW/about-f1.html:text/html},
}


@misc{woodhouse_scary_2022,
	title = {‘{Scary}’ how toxic {Formula} 1 community became during 2021},
	url = {https://www.planetf1.com/news/toxic-formula-1-community-2021/},
	abstract = {Russian Formula 1 commentator Alexey Popov was alarmed by the toxic vibes coming from fans during the 2021 season.},
	language = {en},
	urldate = {2023-01-09},
	journal = {PlanetF1},
	author = {Woodhouse, Jamie},
	month = jan,
	year = {2022},
	note = {Section: News},
	file = {Snapshot:/Users/I516998/Zotero/storage/7J84KHA6/toxic-formula-1-community-2021.html:text/html},
}


@misc{formula_1_2023,
	title = {Formula {One}},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Formula_One&oldid=1132488425},
	abstract = {Formula One (also known as Formula 1 or F1) is the highest class of international racing for open-wheel single-seater formula racing cars sanctioned by the Fédération Internationale de l'Automobile (FIA). The World Drivers' Championship, which became the FIA Formula One World Championship in 1981, has been one of the premier forms of racing around the world since its inaugural season in 1950. The word formula in the name refers to the set of rules to which all participants' cars must conform. A Formula One season consists of a series of races, known as Grands Prix, which take place worldwide on both purpose-built circuits and closed public roads.
A points system is used at Grands Prix to determine two annual World Championships: one for drivers, the other for constructors. Each driver must hold a valid Super Licence, the highest class of racing licence issued by the FIA. The races must run on tracks graded "1" (formerly "A"), the highest grade-rating issued by the FIA.Formula One cars are the fastest regulated road-course racing cars in the world, owing to very high cornering speeds achieved through the generation of large amounts of aerodynamic downforce. Much of this downforce is generated by front and rear wings, which have the side effect of causing severe turbulence behind each car. The turbulence reduces the downforce generated by a car following directly behind, making it hard to overtake. Major changes to the cars for the 2022 season has seen greater use of ground effect aerodynamics, and modified wings to reduce the turbulence behind the cars, with the goal of making overtaking easier. The cars are dependent on electronics and aerodynamics, suspension and tyres. Traction control, launch control, and automatic shifting, plus other electronic driving aids, were first banned in 1994. They were briefly reintroduced in 2001, and have more recently been banned since 2004 and 2008, respectively.With the average annual cost of running a team – designing, building, and maintaining cars, pay, transport – being approximately US\$265 million, its financial and political battles are widely reported. On 23 January 2017, Liberty Media completed its acquisition of the Formula One Group, from private-equity firm CVC Capital Partners for \$8 billion.},
	language = {en},
	urldate = {2023-01-09},
	journal = {Wikipedia},
	month = jan,
	year = {2023},
	note = {Page Version ID: 1132488425},
	file = {Snapshot:/Users/I516998/Zotero/storage/XZZGH4AU/Formula_One.html:text/html},
}


@misc{formula_1_limited_company_profile,
	title = {Formula {One} {World} {Championship} {Ltd} - {Company} {Profile} and {News} - {Bloomberg} {Markets}},
	url = {https://www.bloomberg.com/profile/company/1935454Z:LN},
	urldate = {2023-01-09},
	file = {Formula One World Championship Ltd - Company Profile and News - Bloomberg Markets:/Users/I516998/Zotero/storage/5XU4ACDR/1935454ZLN.html:text/html},
}


@misc{vaswani_attention_2017,
	title = {Attention {Is} {All} {You} {Need}},
	url = {http://arxiv.org/abs/1706.03762},
	doi = {10.48550/arXiv.1706.03762},
	abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
	urldate = {2023-01-12},
	publisher = {arXiv},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
	month = dec,
	year = {2017},
	note = {arXiv:1706.03762 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	annote = {Comment: 15 pages, 5 figures},
	file = {arXiv Fulltext PDF:/Users/I516998/Zotero/storage/B8HZNEVY/Vaswani et al. - 2017 - Attention Is All You Need.pdf:application/pdf},
}

@inproceedings{sst-2,
    title = "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank",
    author = "Socher, Richard  and
      Perelygin, Alex  and
      Wu, Jean  and
      Chuang, Jason  and
      Manning, Christopher D.  and
      Ng, Andrew  and
      Potts, Christopher",
    booktitle = "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing",
    month = oct,
    year = "2013",
    address = "Seattle, Washington, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D13-1170",
    pages = "1631--1642",
}

@inproceedings{wang2019glue,
  title={{GLUE}: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},
  author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R.},
  note={In the Proceedings of ICLR.},
  year={2019}
}