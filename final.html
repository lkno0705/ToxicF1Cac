<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>final</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
    }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<!--

# Final Report - Work in Progress
- Research Hypothesis / Questions:
    - Is Formula 1 fandom Toxic?
    - Are there specific groups that show more toxic behaviour then others?
    - Is the toxicity a "self-made" problem of Formula 1?
- APIs: Youtube
    - (Not reddit as post are often off topic especially during the off season, that we are currently in)
- Methods:
    - TBD
    - Dictionary
        - Formula 1 specific words that are toxic
        - racism / ethnic slurs -> [@ethnic_slurs]
        - toxicity -> [@orthrus-lexicon_orthrus_2022]
        - hate speech -> [@van_der_vegt_grievance_2021]
        - insults -> [@van_der_vegt_grievance_2021]
    - Transformer classifier
        - sentiment -> cardiffnlp/twitter-roberta-base-sentiment-latest [@tweet_sentiment_classifier]
        - hate speech -> Hate-speech-CNERG/dehatebert-mono-english [@racism_classifier]
    - statistical analysis
        - group toxic behavior by drivers and teams
        - group by topics
            - topic modelling?
- Contents:
    - Introduction
        - What is Formula 1
        - Why do we need to analyze this
        - introduce the three research questions / hypothesis
    - Fundamentals
        - Formula 1
        - What is fandom
          - 
        - Defining toxic fan behavior
        - Youtube API
        - Maybe explaining the used methods?
    - Concept
        - What will be done
        - How will i be doing it
    - Creating the Dataset
        - Explain Dataset creation
    - Applying Method 1
    - Applying Method 2
    - Results

-->
<h1
id="analysing-toxicity-in-formula-1-fandom---computational-analysis-of-communications-final">Analysing
Toxicity in Formula 1 Fandom - Computational Analysis of Communications
Final</h1>
<p>Author: Leon Knorr</p>
<p>Matr-Nr: 1902854</p>
<h2 id="disclaimer">Disclaimer</h2>
<p>In order to use Citations in Jupyter Notebook, the whole Notebook has
to be converted to markdown and after that, the markdown file has to be
compiled with LATEX and the bibliography and bibliography style is
injected. Because of that Citations and the bibliography are only
visible in the PDF version of the notebook. However because comments
contain emojis, and other special characters, the output of each code
cell has to be cleared before the notebook is converted otherwise the
pdf compile will fail. In addition to that the formating of the code
cells in the pdf document is not necessarily perfect. As a result,
Citations and bibliography will only be correctly visible in the PDF
version, where as code and its output is only visible in the notebook
source.</p>
<h2 id="introduction">Introduction</h2>
<p>Formula 1 is the highest class of international racing for open-wheel
single-seater formula racing cars and is generally considered the most
competitive, fastest and hardest class of motor racing. Since it’s first
season in 1950, Formula 1 is visiting a diverse list of many different
countries, where the best drivers in the world are racing against each
other in teams of two drivers to determine the best driver and the best
team on the Formula 1 grid <span class="citation"
data-cites="about_f1">(Lowrey, 2019)</span>. These events are visited by
thousands of Fans, with millions more following them on television and
social media. With the 2021 season being one of the closest and most
entertaining seasons in the history of Formula 1, where Red Bulls Max
Verstappen beat Mercedes driver Lewis Hamilton in the grand finale of
the season under controversial circumstances after a full season of
controversy, drama and intense on track battles and with the release of
Netflix Drive To Survive, Formula 1s popularity is growing rapidly. But,
reports of Toxic and abusive Fan behavior at events and in comment
sections on social media are accumulating, and casts an ugly shadow over
Formula 1s latest successes <span class="citation"
data-cites="woodhouse_scary_2022">(Woodhouse, 2022)</span>. As the
reports over toxic and abusive fan behaviours in social media and at
live events are rising, Formula 1 as well as Fans and drivers are taking
a stand against toxicity in the Formula 1 community. However, an
independent and scientific analysis of this topic is missing and
therefore the accusations are sort of hanging in the air without a solid
scientific foundation. Therefore, in order to tackle this problem
research into the toxicity of Formula 1 fandom is a necassety to gain
valuable insights into understanding the problem, where it originates
from and to build a foundation for future measures to make attending
Formula 1 events as well as the media around it a safer and more
enjoyable experience. To take the first step into this direction, this
thesis will analyse Youtube comments of the Formula 1 channel in order
to determine:</p>
<ul>
<li>If the Formula 1 fandom is toxic</li>
<li>Has Toxicity risen over the years?</li>
<li>Is the toxicity a “self-made” problem of Formula 1 and where is the
toxicity originating from?</li>
</ul>
<h2 id="fundamentals">Fundamentals</h2>
<p>In this chapter the necessary fundamental knowledge is presented.</p>
<h3 id="formula-1">Formula 1</h3>
<p>Formula 1 is the worlds most prestigous motor racing competition, as
well as the world’s most popular annual sporting series <span
class="citation" data-cites="about_f1">(Lowrey, 2019)</span>. It marks
the highest class of international open-wheel single-seater formula
racing. The first Formula 1 competition was held in 1950, since then the
competiton for the world drivers championship (wdc) which determines the
worlds best driver and the world constructors championship (wcc) which
determines the best team, is held annualy and is sanctioned by the
Fédération Internationale de l’Automobile (FIA). During the competition
(also called a season), Formula 1 visits a variety of different
countries and racing tracks, each event (Grands Prix) is attended by
thousands of people with millions watching from home <span
class="citation" data-cites="formula_1_2023">(<span>“Formula
<span>One</span>,”</span> 2023)</span>. All rights of the Formula 1
brand and the competition itself is owned by Formula One World
Championship Limited, which is a corporation, that provides media
distribution and promotion services, besides that, it controls the
contracts, distribtution, and commercial management of rights and
licenses of formula 1 <span class="citation"
data-cites="formula_1_limited_company_profile">(<em>Formula
<span>One</span> <span>World</span> <span>Championship</span>
<span>Ltd</span> - <span>Company</span> <span>Profile</span> and
<span>News</span> - <span>Bloomberg</span> <span>Markets</span></em>,
n.d.)</span>. The term Formula 1 is used to describe the corporation, as
well as the competition, as they can’t exist without each other.</p>
<h3 id="what-is-fandom">What is Fandom</h3>
<p>According to Cornel Sandvoss Fandom is a community of people that are
regularly, consuming a given popular narrative or text with great
emotional involvement <span class="citation"
data-cites="toxic_fandom">(<span>“What <span>Is</span>
<span>Toxic</span> <span>Fandom</span>?”</span> n.d.)</span>. The
members of the community are called fans, which is a short form of
“fanatic” <span class="citation" data-cites="arouh_toxic_2020">(Arouh,
2020)</span>. In other words, a fandom is a community of people that are
fanatic about a popular narrative or text such as a tv series, movie
franchise or sports.</p>
<p>Becoming a fan starts with the adoption of a fan identity about a fan
object, thus fandom can be a powerful of defining the self. The fan
object can be anything that people can be fanatic about, this may be a
simple object such as trains or a virtual asset such as a movie
franchise. Therefore, by taking part in a fandom, people are expressing
themselfs through an identity they’ve chosen for themselfs. As a result,
fans may lead to see the fan object as an extension of themselfs and
thus react personally threatened if the fan object is facing a threat
such as accusations etc <span class="citation"
data-cites="toxic_fandom">(<span>“What <span>Is</span>
<span>Toxic</span> <span>Fandom</span>?”</span> n.d.)</span>. In
addition to creating a strong part of their own identity, fans feel more
connected or socialised through their fandom, as studies indicate, that
even if fans don’t interact with other members of a fan community, they
still perceive themselfs as part of that community. Because of that,
fans not only become personally invested in their fandom, they become
socially invested as well <span class="citation"
data-cites="toxic_fandom">(<span>“What <span>Is</span>
<span>Toxic</span> <span>Fandom</span>?”</span> n.d.)</span>.</p>
<p>As a result of the strong connection fans build up to their fan
object, the time-frame in which this self identity has been chosen is
also playing a role. As an example, many people build a fandom in their
childhood about a tv series, franchise or sport, this often leads to
them feeling entitled to having their fan object preserved as they deem
acceptable. This behaviour is also called fan entitlement. A good
example for this behaviour are the news movies and series in the Lord of
the Rings and Star Wars franchises, as most fan communities of these
franchises have been outraged about the new characters and story lines,
where many people claimed that this “ruined their childhood” <span
class="citation" data-cites="toxic_fandom">(<span>“What <span>Is</span>
<span>Toxic</span> <span>Fandom</span>?”</span> n.d.)</span>.</p>
<p>From an economic point of view, fandom and fan cultures are seen as
the ideal costumers. They are eager to get their hands on the newest
products and they are stable with re-occuring purchases, since intense
consumption is considered a part of the fan identity <span
class="citation" data-cites="arouh_toxic_2020">(Arouh, 2020)</span>.</p>
<h3 id="defining-toxic-fan-behaviour">Defining Toxic Fan behaviour</h3>
<p>In the first place, toxic fandom is a buzzword, that is widely used
throughout media to describe or identify fans who engage in behaviors
that are considered negative or unaccaptable. This behavior can range
from simple negative responses to bullying other members of a fandom or
those involved in the creation of the fan object <span class="citation"
data-cites="toxic_fandom">(<span>“What <span>Is</span>
<span>Toxic</span> <span>Fandom</span>?”</span> n.d.)</span>. Most of
this behaviour can be observed online in social media, there are however
reports of toxic behaviour in real-life as well, such as abusive
behaviour at events.</p>
<p>The word toxic itself however is defined as “of relating to, or
caused by a toxin,” “of the nature of a poison; poisonous” <span
class="citation" data-cites="arouh_toxic_2020">(Arouh, 2020)</span>.
This definition originally originates from medival latin, where it
refers to poisoned arrows or to being imbued with poison. Following this
definition, it is an <em>external</em> substance that is toxic and not a
person or their behaviour. However in recent years the understanding of
this definition has shifted, today someones actions or the emotions
experienced or types of character are now understood as poisonous or
“toxic” <span class="citation" data-cites="arouh_toxic_2020">(Arouh,
2020)</span>. This definition is closely related to the definition of
the word fan, as explained earlier, fan originates from fanatic, which
is traditionally linked to madness and demonic posession. This
traditional and long obselete link is often exploited by media outlets
to mark fans as psychopaths whose frustrated fantasies of intimate
relationships or unsatisfied desires with the fan object take violent
and ant-social forms <span class="citation"
data-cites="arouh_toxic_2020">(Arouh, 2020)</span>. In order to maintain
this hypothesis, media often picks the most miserable and negative or
“click-bait” examples of fan behaviour, as it creates the most attention
and keeps the viewing figures high <span class="citation"
data-cites="arouh_toxic_2020">(Arouh, 2020)</span>, <span
class="citation" data-cites="proctor_editors_2018">(Proctor &amp; Kies,
2018)</span>. These circumstances are additionally amplified by social
media plattforms, as they promote toxic behaviour, because it usually
creates a lot of interactions. Therefore, it is our overall
understanding of what a fan is that marks a him as a toxic “other”.</p>
<p>What is also observed, is that “toxic” fans often fall back to racist
and mysogenistic behaviour compared with hate speech in order to defend
their fan object or view point. This often comes with a feeling of
“power loss” for the “toxic fan”. Because of that, current social-,
ideological- and political conflicts are becoming more and more frequent
as a topic in toxic behaviour <span class="citation"
data-cites="proctor_editors_2018">(Proctor &amp; Kies, 2018)</span>,
<span class="citation" data-cites="arouh_toxic_2020">(Arouh,
2020)</span>, <span class="citation"
data-cites="toxic_fandom">(<span>“What <span>Is</span>
<span>Toxic</span> <span>Fandom</span>?”</span> n.d.)</span>. For some
members of the fan communities, this feeling of power loss is amplified
by current political circumstances where they feel a feeling of
disempowerment at their loss of priviliged status in society because of
gender discussions or woman rights movements. Thus toxic fans are often
painted as angry white, heterosexual men or members of the “alt-right”
community. However in many cases, fan communities are used as a
plattform to spread this hatered or ideological ideas because it creates
a lot of attention in social networks as well as from the media. The
media then progresses to paint fandom and online culture as more and
more toxic because it creates “maximum cultural penetration” <span
class="citation" data-cites="proctor_editors_2018">(Proctor &amp; Kies,
2018)</span>. This trend has led to the phenomenon of <em>progressive
toxicity</em>, where other fans “rush to prove one’s moral superiority
by speaking out against some racist, sexist or otherwise hurtful
sentiment, the sentiment is often amplified on a scale that wouldn’t
have been possible had people not taken the bait” <span class="citation"
data-cites="proctor_editors_2018">(Proctor &amp; Kies, 2018)</span>.
This rush to prove morally better than the toxic other often leads to
toxic behavior by the defender itself. Because of that, toxic practices
more and more frequently are instantiations of larger political or
cultural polarizations and they depict the current socio-political
climate. Thus toxic fan behaviour is often observed as a conlflict
between the “political correct” pro-diversity crowd, which are also
called social justice warriors (SJWs) and the members of the so-called
“alt-right” hell-bent <span class="citation"
data-cites="proctor_editors_2018">(Proctor &amp; Kies, 2018)</span>.</p>
<p>However toxic fan behaviour is not limited to racist, misogynistic
comments that can also include hate-speech. Some toxic fan are even
going as far as to writing death or rape threats, doxing people (doxing
refers to leaking personal information online) or to show abusive and
harassing behaviour in public against other groups <span
class="citation" data-cites="proctor_editors_2018">(Proctor &amp; Kies,
2018)</span>, <span class="citation"
data-cites="arouh_toxic_2020">(Arouh, 2020)</span>.</p>
<h2 id="the-dataset">The Dataset</h2>
<p>The dataset that will be used throughout this thesis consists of
40200 Comments with replys from 500 youtube videos that were uploaded
since 2020 of the formula 1 youtube channel. To obtain this data, the
Youtube API V3 was used.</p>
<p>First up, the API has to be initialised, for this an api key is
needed, that has to be stored in a .env file in the same directory as
the jupyter notebook. This api key is then read in the following code
cell and the youtube api is initialized through googles official
googleapiclient library.</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dotenv <span class="im">import</span> dotenv_values</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> googleapiclient.discovery</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>api_keys <span class="op">=</span> dotenv_values(<span class="st">&quot;keys.env&quot;</span>)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>api_service_name <span class="op">=</span> <span class="st">&quot;youtube&quot;</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>api_version <span class="op">=</span> <span class="st">&quot;v3&quot;</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>api_key <span class="op">=</span> api_keys[<span class="st">&quot;YOUTUBE_API_KEY&quot;</span>]</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>max_results <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>youtube_api <span class="op">=</span> googleapiclient.discovery.build(api_service_name, api_version, developerKey <span class="op">=</span> api_key)</span></code></pre></div>
<p>Now request to the Youtube API V3 can be made. Before we can scrape
comments, the video id of the video that comments want to be obtain from
is needed. Therefore, data about all videos since 2020 until now are
requested. However the api will only retrieve 50 items per request, if
there are more items that fit the search query the response is paged and
contains a <em>nextPageToken</em>, that can be used to obtain the next
50 items. Requesting all videos since 2020 allows the dataset to span a
timeframe of three years and will allow to analyze toxicity over time as
well and will also paint a broader picture of how the F1 fandom
developed. After obtaining all video information, the video ids are
extracted and safed into a list, which is used later to obtain the
actual comment threads.</p>
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>Formula1_official_channel <span class="op">=</span> youtube_api.channels().<span class="bu">list</span>(part<span class="op">=</span><span class="st">&#39;snippet&#39;</span> ,forUsername<span class="op">=</span><span class="st">&#39;Formula1&#39;</span>).execute()[<span class="st">&#39;items&#39;</span>][<span class="dv">0</span>]</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>videos_after_2020 <span class="op">=</span> youtube_api.search().<span class="bu">list</span>(channelId<span class="op">=</span>Formula1_official_channel[<span class="st">&quot;id&quot;</span>],</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>        maxResults<span class="op">=</span>max_results,</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>        publishedAfter<span class="op">=</span><span class="st">&quot;2020-01-01T00:00:00Z&quot;</span>,</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>        part<span class="op">=</span><span class="st">&#39;id&#39;</span>).execute()</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>video_ids_after_2020 <span class="op">=</span> [item[<span class="st">&#39;id&#39;</span>][<span class="st">&#39;videoId&#39;</span>] <span class="cf">for</span> item <span class="kw">in</span> videos_after_2020[<span class="st">&#39;items&#39;</span>]]</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="cf">while</span> <span class="bu">len</span>(video_ids_after_2020) <span class="op">&lt;</span> max_results <span class="kw">and</span> <span class="st">&quot;nextPageToken&quot;</span> <span class="kw">in</span> videos_after_2020.keys():</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>        videos_after_2020 <span class="op">=</span> youtube_api.search().<span class="bu">list</span>(channelId<span class="op">=</span>Formula1_official_channel[<span class="st">&quot;id&quot;</span>],</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>        maxResults<span class="op">=</span>max_results,</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>        publishedAfter<span class="op">=</span><span class="st">&quot;2020-01-01T00:00:00Z&quot;</span>,</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>        part<span class="op">=</span><span class="st">&#39;id&#39;</span>,</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>        pageToken<span class="op">=</span>videos_after_2020[<span class="st">&quot;nextPageToken&quot;</span>]).execute()</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>        video_ids_after_2020 <span class="op">=</span> video_ids_after_2020 <span class="op">+</span> [item[<span class="st">&#39;id&#39;</span>][<span class="st">&#39;videoId&#39;</span>] <span class="cf">for</span> item <span class="kw">in</span> videos_after_2020[<span class="st">&#39;items&#39;</span>]]</span></code></pre></div>
<p>Besides the list of video ids, the data is also parsed into a
dataframe. This allows to take general video information such as like
count, video title, the overall comment count etc. into consideration
for the final analysis.</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>df_list <span class="op">=</span> []</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> video_id <span class="kw">in</span> video_ids_after_2020:</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    video_data <span class="op">=</span> youtube_api.videos().<span class="bu">list</span>(part<span class="op">=</span><span class="st">&#39;snippet, statistics&#39;</span>, <span class="bu">id</span><span class="op">=</span>video_id).execute()</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    snippet <span class="op">=</span> video_data[<span class="st">&#39;items&#39;</span>][<span class="dv">0</span>][<span class="st">&#39;snippet&#39;</span>]</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    statistics <span class="op">=</span> video_data[<span class="st">&#39;items&#39;</span>][<span class="dv">0</span>][<span class="st">&#39;statistics&#39;</span>]</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    df_list.append(</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;video_id&quot;</span>:video_id,</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;title&quot;</span>: snippet[<span class="st">&#39;title&#39;</span>],</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;description&quot;</span>: snippet[<span class="st">&#39;description&#39;</span>],</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;channel&quot;</span>: snippet[<span class="st">&#39;channelTitle&#39;</span>],</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;published_at&quot;</span>: snippet[<span class="st">&#39;publishedAt&#39;</span>],</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;tags&quot;</span>: snippet[<span class="st">&#39;tags&#39;</span>] <span class="cf">if</span> <span class="st">&quot;tags&quot;</span> <span class="kw">in</span> snippet.keys() <span class="cf">else</span> <span class="va">None</span>,</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;like_count&quot;</span>: statistics[<span class="st">&#39;likeCount&#39;</span>],</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;favorite_count&quot;</span>: statistics[<span class="st">&#39;favoriteCount&#39;</span>],</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;comment_count&quot;</span>: statistics[<span class="st">&#39;commentCount&#39;</span>] <span class="cf">if</span> <span class="st">&quot;commentCount&quot;</span> <span class="kw">in</span> statistics.keys() <span class="cf">else</span> <span class="dv">0</span></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>videos <span class="op">=</span> pd.DataFrame(df_list)</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>videos</span></code></pre></div>
<p>Now that all the necessary video information has been obtained, the
actual comments and replys can be requested. In order to achieve this,
for every video id that has been retrieved earlier, a list of 15 comment
threads is requested. Every comment thread consists of a topcomment,
that has a number of replys associated with it. Because of the maximum
quota of 10000 request units per day, for each video only 15 comments
can be obtained, as each comment request costs one unit, for all 500
videos for 15 commenthreads per video, a quota usage of 7500 applies.
Now for each retrieved top comment a maximum of 10 replies are
requested. The corresponding data, is then parsed into one large
dataframe, that contains the comment text as well as administrative
information like the video id as well as the comment id and further
useful information like the number of likes a comment / reply has or the
publishing date. This additional information allows to further reason
about the amount of interaction the particular comment got.</p>
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>df_list_comments <span class="op">=</span> []</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> video_id <span class="kw">in</span> video_ids_after_2020:</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> videos.loc[videos[<span class="st">&#39;video_id&#39;</span>] <span class="op">==</span> video_id].comment_count.iloc[<span class="dv">0</span>] <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>        <span class="cf">continue</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>    top_level_comments <span class="op">=</span> youtube_api.commentThreads().<span class="bu">list</span>(part<span class="op">=</span><span class="st">&quot;snippet&quot;</span>,</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>        maxResults<span class="op">=</span><span class="dv">15</span>,</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>        order<span class="op">=</span><span class="st">&quot;relevance&quot;</span>,</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>        videoId<span class="op">=</span>video_id).execute()[<span class="st">&#39;items&#39;</span>]</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> top_level_comment <span class="kw">in</span> top_level_comments:</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>        replies <span class="op">=</span> youtube_api.comments().<span class="bu">list</span>(part<span class="op">=</span><span class="st">&quot;snippet&quot;</span>,</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>            maxResults<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>            parentId<span class="op">=</span>top_level_comment[<span class="st">&#39;snippet&#39;</span>][<span class="st">&#39;topLevelComment&#39;</span>][<span class="st">&#39;id&#39;</span>]).execute()[<span class="st">&#39;items&#39;</span>]</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>        df_list_comments.append(</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>        {</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;video_id&quot;</span>: video_id,</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;id&quot;</span>: top_level_comment[<span class="st">&#39;snippet&#39;</span>][<span class="st">&#39;topLevelComment&#39;</span>][<span class="st">&#39;id&#39;</span>],</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;text&quot;</span>: top_level_comment[<span class="st">&#39;snippet&#39;</span>][<span class="st">&#39;topLevelComment&#39;</span>][<span class="st">&#39;snippet&#39;</span>][<span class="st">&#39;textDisplay&#39;</span>],</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;user&quot;</span>: top_level_comment[<span class="st">&#39;snippet&#39;</span>][<span class="st">&#39;topLevelComment&#39;</span>][<span class="st">&#39;snippet&#39;</span>][<span class="st">&#39;authorChannelId&#39;</span>][<span class="st">&#39;value&#39;</span>],</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;like_count&quot;</span>: top_level_comment[<span class="st">&#39;snippet&#39;</span>][<span class="st">&#39;topLevelComment&#39;</span>][<span class="st">&#39;snippet&#39;</span>][<span class="st">&#39;likeCount&#39;</span>],</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;published_at&quot;</span>: top_level_comment[<span class="st">&#39;snippet&#39;</span>][<span class="st">&#39;topLevelComment&#39;</span>][<span class="st">&#39;snippet&#39;</span>][<span class="st">&#39;publishedAt&#39;</span>],</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;reply_count&quot;</span>: top_level_comment[<span class="st">&#39;snippet&#39;</span>][<span class="st">&#39;totalReplyCount&#39;</span>]</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>        })</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> reply <span class="kw">in</span> replies:</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>            df_list_comments.append(</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>            {</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>                <span class="st">&quot;video_id&quot;</span>: video_id,</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>                <span class="st">&quot;id&quot;</span>: reply[<span class="st">&#39;id&#39;</span>],</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>                <span class="st">&quot;text&quot;</span>: reply[<span class="st">&#39;snippet&#39;</span>][<span class="st">&#39;textDisplay&#39;</span>],</span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>                <span class="st">&quot;user&quot;</span>: reply[<span class="st">&#39;snippet&#39;</span>][<span class="st">&#39;authorChannelId&#39;</span>][<span class="st">&#39;value&#39;</span>],</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>                <span class="st">&quot;like_count&quot;</span>: reply[<span class="st">&#39;snippet&#39;</span>][<span class="st">&#39;likeCount&#39;</span>],</span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>                <span class="st">&quot;published_at&quot;</span>: reply[<span class="st">&#39;snippet&#39;</span>][<span class="st">&#39;publishedAt&#39;</span>],</span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>                <span class="st">&quot;reply_count&quot;</span>: <span class="dv">0</span></span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a>            })</span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a>comment_df: pd.DataFrame <span class="op">=</span> pd.DataFrame(df_list_comments)</span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a>comment_df</span></code></pre></div>
<p>Last but not least the dataset is saved into a “pickle” file, which
allows efficient storage of dataframes. This is especially useful if the
notebook has to be restarted because the dataset doesn’t has to be build
from scratch and no quota or api access is required to perform analysis
on the dataset.</p>
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>videos.to_pickle(<span class="st">&quot;datasets/video_data.pkl&quot;</span>)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>comment_df.to_pickle(<span class="st">&quot;datasets/comment_data.pkl&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>videos: pd.DataFrame <span class="op">=</span> pd.read_pickle(<span class="st">&quot;datasets/video_data.pkl&quot;</span>)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>comment_df: pd.DataFrame <span class="op">=</span> pd.read_pickle(<span class="st">&quot;datasets/comment_data.pkl&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>videos</span></code></pre></div>
<h3 id="dataset-limitations">Dataset limitations</h3>
<p>Because of the quoate limit google has set for the youtube api, the
dataset is only depicting a small section of the actual circumstances in
the Formula 1 fandom. For example, for one video, a maximum of <span
class="math inline">15 * 10 = 150</span> comments will be retrieved.</p>
<div class="sourceCode" id="cb8"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>videos.comment_count <span class="op">=</span> videos.comment_count.astype(<span class="bu">int</span>)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>videos.comment_count.mean()</span></code></pre></div>
<p>However, on average a video has 1250 comments. Thus a lot of fan
interaction will be missed and is not included in this dataset. In
addition to that, the dataset only uses the Youtube API as a source,
however Formula 1 fandom spans over multiple platforms, especially
Twitter, Instagram and Reddit. Thus it is possible that depending on the
plattform toxic user interactions may be more frequent as they are
governed differently. Also, as Formula 1 is an international sport,
comments may not be in english, the dataset therefore must be considered
multilingual, which can be problematic depending on the methods used.
Nevertheless the dataset spans over a total of 40200 comments that can
be analysed.</p>
<h2 id="dictionary-analysis">Dictionary Analysis</h2>
<p>As the first method to analyze the dataset, a dictionary analysis is
performed. For this, the following three different online available
dictionaries are used:</p>
<ul>
<li>Othrus Lexicon for Toxicity <span class="citation"
data-cites="orthrus-lexicon_orthrus_2022">(Orthrus-Lexicon,
2022)</span>, to classify toxic texts directly</li>
<li>the Grievance Dictionary <span class="citation"
data-cites="van_der_vegt_grievance_2021">(Vegt et al., 2021)</span>, to
classify different categories of negative or unacceptable behaviour</li>
<li>a dictionary of ethnic slurs based of wikipedia <span
class="citation" data-cites="ethnic_slurs">(<span>“List of Ethnic
Slurs,”</span> 2023)</span>, to find toxic behaviour based on
racism</li>
</ul>
<p>In order to achieve a fast and reusable way of analysing comments
with any of the given dictionaries, each dictionary and comment text
will be represented as a set. Between those two sets, the set
intersection is computed, which contains all words that are found in the
dictionary and in the comment text. Thus it essentially checks for word
occurence. The number of words from the dictionary is then added to the
result dataframe. In addition to that, a global counter tracks the
number of overall occurences of each dictionary word. This allows for
the analysis of language biases or trends in Formula 1 fandom. This
method is used for all given dictionaries.</p>
<div class="sourceCode" id="cb9"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> typing <span class="im">import</span> Tuple</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk <span class="im">import</span> word_tokenize</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> dictionary_analysis_over_set_intersection(dict_name: <span class="bu">str</span>, dict_set: <span class="bu">set</span>, data: pd.DataFrame) <span class="op">-&gt;</span> Tuple[pd.DataFrame, Counter]:</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>    dict_word_counter: Counter <span class="op">=</span> Counter()</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>    dict_word_count: <span class="bu">list</span> <span class="op">=</span> []</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> row <span class="kw">in</span> data.text:</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>        dict_words_in_comment: <span class="bu">set</span> <span class="op">=</span> <span class="bu">set</span>(word_tokenize(row)).intersection(dict_set)</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>        dict_word_counter.update(dict_words_in_comment)</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>        dict_word_count.append(<span class="bu">len</span>(dict_words_in_comment))</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>    data[<span class="ss">f&quot;</span><span class="sc">{</span>dict_name<span class="sc">}</span><span class="ss">_word_count&quot;</span>] <span class="op">=</span> dict_word_count</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> data, dict_word_counter</span></code></pre></div>
<h3 id="othrus-lexicon-for-toxicity">Othrus-Lexicon for Toxicity</h3>
<p>The Othrus-Lexicon for Toxicity is a dictionary containing words
often used throughout the internet in toxic content <span
class="citation"
data-cites="orthrus-lexicon_orthrus_2022">(Orthrus-Lexicon,
2022)</span>. It contains about 1900 words that include slurs, insults
and common internet abbreviations and obfuscations, such as “sh*t”,
which are used to bypass automatic content moderation systems. Other
then the Github page, nothing else can be found on the internet about
this dictionary, therefore nothing is known about creation process or if
and how the dictinoary has been validated. Nonetheless it will be used
during this thesis to provide additional insights into the toxicity of
Formula 1 fandom as it fits the topic perfectly but its results have to
be treated with caution.</p>
<p>In order to use the Othrus-Lexicon for Toxicity, the dictionary has
to be read from the provided “toxic_words.txt” text file and is then
converted into a set. The set conversion will remove duplicates and
ensures compatibility with the previously introduced method of set
intersection for word occurence, which is used to analyse the
dataset.</p>
<div class="sourceCode" id="cb10"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(<span class="st">&quot;dictionaries/toxic_words.txt&quot;</span>) <span class="im">as</span> toxic_words_file:</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>    set_of_toxic_words: <span class="bu">set</span> <span class="op">=</span> <span class="bu">set</span>([word.strip() <span class="cf">for</span> word <span class="kw">in</span> toxic_words_file.readlines()])</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>set_of_toxic_words</span></code></pre></div>
<div class="sourceCode" id="cb11"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>comment_df, toxic_word_counter <span class="op">=</span> dictionary_analysis_over_set_intersection(dict_name<span class="op">=</span><span class="st">&quot;toxic&quot;</span>, dict_set<span class="op">=</span>set_of_toxic_words, data<span class="op">=</span>comment_df)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>comment_df.loc[comment_df[<span class="st">&quot;toxic_word_count&quot;</span>] <span class="op">&gt;</span> <span class="dv">0</span>]</span></code></pre></div>
<div class="sourceCode" id="cb12"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>toxic_word_counter</span></code></pre></div>
<h3 id="grievance-dictionary">Grievance Dictionary</h3>
<p>The Grievance Dictionary proposed by van der Vegt et. al. aims to
provide a method to automatically understand language use in the context
of grievance-fuelled violence threat assessement <span class="citation"
data-cites="van_der_vegt_grievance_2021">(Vegt et al., 2021)</span>. It
has been created out of informed suggestions from experienced threat
assesement practitioners in combination with subsequent humand and
computational word list generation. The resulting dictionary includes
20502 words which were annotated by 2318 participants. In its validation
process, it was applied to texts written by violent and non-violent
individuals. The results showed strong evidence for a high
classification performance <span class="citation"
data-cites="van_der_vegt_grievance_2021">(Vegt et al., 2021)</span>.</p>
<p>The dictionary itself is composed of multiple categories which depict
different forms of grievance, for example jealousy or threat. Each
category includes a number of word stems, annotated with weights, which
indicate how important or meaningful the given word is for the category
it is included in. There are two version of the dictionary available,
one which includes words with weights of five or higher and one which
includes words with weights of seven or higher. During this thesis the
dictionary with weights higher than five will be used, as it can
hypothetically cover more infrequent and domain specific words. The
dictionary can support three different approaches to text classification
<span class="citation" data-cites="van_der_vegt_grievance_2021">(Vegt et
al., 2021)</span>:</p>
<ul>
<li><strong>Proportional Scoring</strong>: Proportional scoring or
wordcount-based classification, calculates the proportion of grievance
fueled words in the given texts. This proportion is then used as a
classification measure.</li>
<li><strong>Weight-based</strong>: During this approach, the assigned
word weights are used to obtain a weight average for each given text,
which is used as the classification measure.</li>
<li><strong>Word inclusion</strong>: Word inclusion checks if and how
often the given words from the dictionary are included in the text.</li>
</ul>
<p>In order to be able to analyse the dataset with the grievance
dictionary, all comment texts have to be stemmed. For that, the
Porterstemmer, word_tokenize and TreebankWordDetokenizer from the
natural language toolkit will be used. First, the comment dataset will
be copied, this ensures, that the original texts won’t be affected by
the applied dictionary specific processing. Then, the text column will
be manipulated through the swifter module, which ensures efficient and
automatic parrallelization. During manipulation, the text is split up
into tokens, then converted to its word stem by the Porterstemmer and
detokenized by the TreebankWordDetokenizer. This process essentially
converts the original text into the same text sequence but it is
composed of word stems instead of the actual words.</p>
<div class="sourceCode" id="cb13"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.stem <span class="im">import</span> PorterStemmer</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk <span class="im">import</span> word_tokenize</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk <span class="im">import</span> TreebankWordDetokenizer</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> swifter</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>stemmer: PorterStemmer <span class="op">=</span> PorterStemmer()</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>detokenizer: TreebankWordDetokenizer <span class="op">=</span> TreebankWordDetokenizer()</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>stemmed_comments: pd.DataFrame <span class="op">=</span> comment_df.copy()</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>stemmed_comments[<span class="st">&quot;text&quot;</span>] <span class="op">=</span> stemmed_comments.text.swifter.<span class="bu">apply</span>(<span class="kw">lambda</span> text: detokenizer.detokenize([stemmer.stem(word) <span class="cf">for</span> word <span class="kw">in</span> word_tokenize(text)]))</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>stemmed_comments</span></code></pre></div>
<p>After preprocessing the dataset, the grievance dictionary can be
loaded. As it is stored in a .csv file, the pandas read_csv function can
be used to read the dictionary into memory. However, the csv includes a
seperate unnamed index, which needs to be dropped.</p>
<div class="sourceCode" id="cb14"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> defaultdict</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> typing <span class="im">import</span> Dict</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>grievance_dict_df <span class="op">=</span> pd.read_csv(<span class="st">&quot;dictionaries/grievancedictionary/dictionary_versions/dictionary_5plus.csv&quot;</span>)</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>grievance_dict_df.drop([<span class="st">&quot;Unnamed: 0&quot;</span>], axis<span class="op">=</span><span class="dv">1</span>, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>categorys <span class="op">=</span> grievance_dict_df.category.unique()</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>categorys</span></code></pre></div>
<p>As the dictionary made up of several categories, a set for each
dictionary category has to be created in order to ensure compatibility
with the dictionary over set intersection function, that was presented
earlier. Now for each category, the texts are analyzed using this
method. However instead of saving one counter, that counts word
occurences, a dictionary which stores each counter for its given
category.</p>
<div class="sourceCode" id="cb15"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm <span class="im">import</span> tqdm</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>grievance_set_dictionary: Dict[<span class="bu">str</span>, Counter] <span class="op">=</span> defaultdict(Counter)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> category <span class="kw">in</span> tqdm(categorys):</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>    curr_category_set <span class="op">=</span> <span class="bu">set</span>(grievance_dict_df.loc[grievance_dict_df.category <span class="op">==</span> category].word.to_list())</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>    stemmed_comments, grievance_set_dictionary[category] <span class="op">=</span> dictionary_analysis_over_set_intersection(dict_name<span class="op">=</span>category, dict_set<span class="op">=</span>curr_category_set, data<span class="op">=</span>stemmed_comments)</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>stemmed_comments</span></code></pre></div>
<p>Last but not least, the results stored in the stemmed dataset needs
to be merged into the original one using the pd.merge function.</p>
<div class="sourceCode" id="cb16"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>comment_df <span class="op">=</span> pd.merge(comment_df, stemmed_comments[[<span class="st">&quot;deadline_word_count&quot;</span>, <span class="st">&quot;desperation_word_count&quot;</span>, <span class="st">&quot;fixation_word_count&quot;</span>, <span class="st">&#39;frustration_word_count&#39;</span>, <span class="st">&#39;god_word_count&#39;</span>,</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>       <span class="st">&#39;grievance_word_count&#39;</span>, <span class="st">&#39;hate_word_count&#39;</span>, <span class="st">&#39;help_word_count&#39;</span>, <span class="st">&#39;honour_word_count&#39;</span>, <span class="st">&#39;impostor_word_count&#39;</span>, <span class="st">&#39;jealousy_word_count&#39;</span>,</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>       <span class="st">&#39;loneliness_word_count&#39;</span>, <span class="st">&#39;murder_word_count&#39;</span>, <span class="st">&#39;paranoia_word_count&#39;</span>, <span class="st">&#39;planning_word_count&#39;</span>, <span class="st">&#39;relationship_word_count&#39;</span>,</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>       <span class="st">&#39;soldier_word_count&#39;</span>, <span class="st">&#39;suicide_word_count&#39;</span>, <span class="st">&#39;surveillance_word_count&#39;</span>, <span class="st">&#39;threat_word_count&#39;</span>, <span class="st">&#39;violence_word_count&#39;</span>,</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>       <span class="st">&#39;weaponry_word_count&#39;</span>]], left_index<span class="op">=</span><span class="va">True</span>, right_index<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(comment_df)</span></code></pre></div>
<h3 id="ethnic-slurs">Ethnic Slurs</h3>
<p>The third dictionary to be used has been created out of a scrape of
the wikipedia page for ethnic slurs <span class="citation"
data-cites="ethnic_slurs">(<span>“List of Ethnic Slurs,”</span>
2023)</span>. The page list all known ethnix slurs in alphabetical
order, including their targets, meaning and origin. In order to scrape
the website, the webbased tool <a
href="https://wikitable2csv.ggor.de">wikitable2csv</a> has been used.
This tool allows the conversion of tables on wiki websites into .csv
files. As Wikipedia lists every slur in alphabetical order with one
table per letter, a total of 26 .csv files are created. Thus, in order
to use the dictionary, all .csv files are in the directory are listed
and loaded into their own dataframe, which are then concatinated to form
one big dictionary of ethnic slurs.</p>
<div class="sourceCode" id="cb17"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> os <span class="im">import</span> listdir</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os.path</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>dict_files: <span class="bu">list</span> <span class="op">=</span> <span class="bu">list</span>(<span class="bu">filter</span>(<span class="kw">lambda</span> f: f[<span class="op">-</span><span class="dv">4</span>:] <span class="op">==</span> <span class="st">&quot;.csv&quot;</span> ,listdir(<span class="st">&quot;dictionaries/ethnic_slurs/&quot;</span>)))</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>dict_df: pd.DataFrame <span class="op">=</span> pd.DataFrame()</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> <span class="bu">file</span> <span class="kw">in</span> dict_files:</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>    part <span class="op">=</span> pd.read_csv(os.path.join(<span class="st">&quot;dictionaries/ethnic_slurs&quot;</span>, <span class="bu">file</span>))</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>    dict_df <span class="op">=</span> pd.concat([part, dict_df])</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>dict_df.reset_index(inplace<span class="op">=</span><span class="va">True</span>, drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>dict_df</span></code></pre></div>
<p>Now, to be able to reuse the dictionary over set intersection method,
the list of terms / slurs in the dictionary are converted into set and
then passed onto the method alongside the comment dataset.</p>
<div class="sourceCode" id="cb18"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>ethnic_slurs_set: <span class="bu">set</span> <span class="op">=</span> <span class="bu">set</span>(dict_df.Term.to_list())</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>comment_df, ethnic_slurs_counter <span class="op">=</span> dictionary_analysis_over_set_intersection(dict_name<span class="op">=</span><span class="st">&quot;ethnic_slurs&quot;</span>, dict_set<span class="op">=</span>ethnic_slurs_set, data<span class="op">=</span>comment_df)</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>comment_df.loc[comment_df[<span class="st">&quot;ethnic_slurs_word_count&quot;</span>] <span class="op">&gt;</span> <span class="dv">0</span>]</span></code></pre></div>
<div class="sourceCode" id="cb19"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>ethnic_slurs_counter</span></code></pre></div>
<p>After the dataset has been analysed with all three dictionaries, the
resulting dataframe, that includes the dictionary word overlap counts
per comment, is saved to disk. This allows for efficient reloading
without the need of reexecution for the analysis of the acquired
data.</p>
<div class="sourceCode" id="cb20"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>comment_df.to_csv(<span class="st">&quot;datasets/comment_df_dicts.csv&quot;</span> ,index<span class="op">=</span><span class="va">False</span>)</span></code></pre></div>
<h2 id="transformer-classifiers">Transformer Classifiers</h2>
<p>As the second method for analysing the dataset, two transformer based
text classifiers are used. One which classifies the sentiment of a given
comment by marking it positive or negative and one which classifies the
comment as hate speech or not.</p>
<p>A Transformer is an attention based machine learning architecture,
that is made of multiple layers of encoders and decoders. A given text
is first transformed into a basic numerical representation, which is
enriched with positional information. This representation also called
encoding, is then passed on to the stack of <span
class="math inline"><em>n</em></span> encoders, which compute an
information rich embedding. This embedding represents the texts meaning,
words and other metadata in multi-dimensional space. It is then injected
into the decoder stack, which generates a new text sequence, based of
already generated characters and the embedding from the encoders <span
class="citation" data-cites="vaswani_attention_2017">(Vaswani et al.,
2017)</span>. Today, many variations of the original transformer
architecture exist, some are only using the encoder stack, while others
only use the decoder stack. The most well known variations are BERT
(Bi-directional Encoder Representations for Transformers) and Open-AIs
GPT (Generative Pre-Trained Transformer).</p>
<p>In order to use the dataset with transformer models, some
pre-processing has to be applied. It consists of removing html or other
structured script language content, links and anonymizing user mentions.
In addition to cleaning the input texts, some comments have to be
removed from the overall dataset, as they are either in a different
language or consist of unreadable gibberish, which leads to issues while
running some transformer models.</p>
<div class="sourceCode" id="cb21"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoModelForSequenceClassification, AutoTokenizer, AutoConfig</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.special <span class="im">import</span> softmax</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> swifter</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> bs4 <span class="im">import</span> BeautifulSoup</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> preprocess(text):</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>    new_text <span class="op">=</span> []</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>    text <span class="op">=</span> BeautifulSoup(text, <span class="st">&quot;lxml&quot;</span>).text</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t <span class="kw">in</span> text.split(<span class="st">&quot; &quot;</span>):</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>        t <span class="op">=</span> <span class="st">&#39;@user&#39;</span> <span class="cf">if</span> t.startswith(<span class="st">&#39;@&#39;</span>) <span class="kw">and</span> <span class="bu">len</span>(t) <span class="op">&gt;</span> <span class="dv">1</span> <span class="cf">else</span> t</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>        t <span class="op">=</span> <span class="st">&#39;http&#39;</span> <span class="cf">if</span> t.startswith(<span class="st">&#39;http&#39;</span>) <span class="cf">else</span> t</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>        new_text.append(t)</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="st">&quot; &quot;</span>.join(new_text)</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Delete unreadable comments that result in the models crashing</span></span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>comment_df.drop([<span class="dv">14603</span>], inplace<span class="op">=</span><span class="va">True</span>) <span class="co"># comment is full of random characters</span></span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>comment_df.drop([<span class="dv">27224</span>, <span class="dv">27223</span>], inplace<span class="op">=</span><span class="va">True</span>) <span class="co"># comment is not in english</span></span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a>comment_df.reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a>comment_df_for_transformers <span class="op">=</span> comment_df.copy()</span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a>comment_df_for_transformers[<span class="st">&quot;text&quot;</span>] <span class="op">=</span> comment_df_for_transformers.text.swifter.<span class="bu">apply</span>(<span class="kw">lambda</span> text: preprocess(text))</span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>comment_df_for_transformers</span></code></pre></div>
<h3 id="sentiment">Sentiment</h3>
<p>The first transformer model is used to classify the sentiment of a
given comment into positive or negative. Even though this is not a
direct classification of typical toxic behaviour like racism or hate
speech as sorrow text will also be classified as negative, it still
hints towards the overall sentiment inside Formula 1 fandom.</p>
<p>The text-classification transformer used in this thesis is the
“distilbert-base-uncased-finetuned-sst-2-english” <span class="citation"
data-cites="distilbert_sentiment">(HF Canonical Model Maintainers,
2022)</span> model. It is a fine-tuned version of the
“DistilBERT-base-uncased” on the SST-2 (Stanford Sentiment Treebank
corpus) <span class="citation" data-cites="sst-2">(Socher et al.,
2013)</span> for sentiment classification. The model has been validated
on SST-2 as, well as on the GLUE (General Language Understanding
Evaluation Benchmark)<span class="citation"
data-cites="wang2019glue">(Wang et al., 2019)</span>. On both Datasets,
the model reaches scores over 0.9 (1 being the highest possible score)
across the board, with scores around 0.98 in all metrics for sentiment
classification <span class="citation"
data-cites="distilbert_sentiment">(HF Canonical Model Maintainers,
2022)</span>. However it can only work with english text. Besides the
proven classification performance, the model can produce biased
predictions. As an example, in this map (taken from: <span
class="citation" data-cites="distilbert_sentiment">(HF Canonical Model
Maintainers, 2022)</span>): <img src="./images/map.jpeg"
alt="prediction_map" /> the prediction scores for producing a positive
sentiment per <em>country name</em> are depicted. It can be observed,
that the probabilisty vary drastically between different countries. It
has been shown, that for the sentence “This film was filmed in COUNTRY”,
“France” will produce a positive label with a probability of 0.89 but
“Afghanistan” will only produce a positive label with a probability of
0.08, even though nothig in the text hinted at a semantic shift <span
class="citation" data-cites="distilbert_sentiment">(HF Canonical Model
Maintainers, 2022)</span>. As these kind of models are trained
unsupervised, this is an unintentional side-effect. Nonetheless, the
model is a powerful, reliable and well tested sentiment classifier and
will thus be used during this thesis.</p>
<p>An alternative to the distilbert-base-uncased-finetuned-sst-2-english
are models like the “cardiffnlp/twitter-roberta-base-sentiment-latest”
<span class="citation" data-cites="tweet_sentiment_classifier">(Barbieri
et al., 2020)</span> model, that has been trained to classifiy tweets
this included working with emojis, irony, offensive language and
hatespeech, which would in theory be a better fit for the domain of this
research. However, the model has been shown to produce scores around
0.65 or lower, which is comparatively low for sentiment classification
tasks. Besides that, no bias analysis has been done on the model or the
train dataset <span class="citation"
data-cites="tweet_sentiment_classifier">(Barbieri et al., 2020)</span>,
which poses a risk in using this model, especially as twitter has been
shown to be a plattform that includes a lot of toxicity and hateful
content [arouh_toxic_2020]. In addition to that, the tokenizer of the
model has been trained without a truncation token ([TRUNC]), which is
used to trim text sequences that are longer than the supported maximum
length of the model. In the initial release, this hasn’t been a problem
as the average tweet in the dataset is reported to be 100 tokens long,
and the models maximum length is at 512 tokens. However, the Youtube
comments included in the acquired dataset have often shown to produce
longer sequences than 512 tokens and thus are in need to use the
truncation token. But, using the truncation token produces a vocabulary
length mismatch between the tokenizer and the model, which leads to the
model crashing during processing.</p>
<p>In order to implement the
distilbert-base-uncased-finetuned-sst-2-english the common
“Huggingface”, also called “pytorch-transformers” library is used. It
enables fast and easy access to hundreds of models available on the
Huggingface model hub. First up, the tokenizer, config and model are
initialized with the pre-trained weights available on the model hub for
the distilbert-base-uncased-finetuned-sst-2-english model. Now every
comment is fed sequentially into the model by first encoding it with the
tokenizer and then passing the encoded input through the actual
transformer model. This will return a tensor with classification
information as well as further metadata. The classification data is
extracted from the model und run through a softmax to obtain the actual
prediction scores for the classes, which are represented by their vector
positions. The vector is then sorted via an argsort to obtain the
highest vector position, which is converted into the actual label. Both
the score and the label are then appended to a score and label list,
which are injected into the global data frame at the end of the
processing loop.</p>
<div class="sourceCode" id="cb22"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm <span class="im">import</span> tqdm</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>MODEL <span class="op">=</span> <span class="st">&quot;distilbert-base-uncased-finetuned-sst-2-english&quot;</span></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>config <span class="op">=</span> AutoConfig.from_pretrained(MODEL)</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(MODEL)</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AutoModelForSequenceClassification.from_pretrained(MODEL)</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>label_list <span class="op">=</span> []</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>score_list <span class="op">=</span> []</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> text <span class="kw">in</span> tqdm(comment_df_for_transformers.text.to_list()):</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>    encoded_input <span class="op">=</span> tokenizer(text, return_tensors<span class="op">=</span><span class="st">&#39;pt&#39;</span>, padding<span class="op">=</span><span class="va">True</span>, truncation<span class="op">=</span><span class="va">True</span>, max_length<span class="op">=</span><span class="dv">512</span>)</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>    output <span class="op">=</span> model(<span class="op">**</span>encoded_input)</span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a>    scores <span class="op">=</span> output[<span class="dv">0</span>][<span class="dv">0</span>].detach().numpy()</span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>    scores <span class="op">=</span> softmax(scores)</span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a>    label_list.append(config.id2label[np.argsort(scores)[::<span class="op">-</span><span class="dv">1</span>][<span class="dv">0</span>]])</span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a>    score_list.append(<span class="bu">max</span>(scores))</span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a>comment_df[<span class="st">&quot;sentiment&quot;</span>] <span class="op">=</span> label_list</span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a>comment_df[<span class="st">&quot;sentiment_score&quot;</span>] <span class="op">=</span> score_list</span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true" tabindex="-1"></a>comment_df</span></code></pre></div>
<div class="sourceCode" id="cb23"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>comment_df.to_csv(<span class="st">&quot;datasets/comment_df_sentiment_transformer.csv&quot;</span> ,index<span class="op">=</span><span class="va">False</span>) <span class="co"># df caching to save processing time on reload</span></span></code></pre></div>
<h3 id="hate-speech">Hate Speech</h3>
<p>The second transformer classifier used during this thesis is the
“Hate-speech-CNERG/dehatebert-mono-english” transformer. It aims to
classify into hate speech containing texts and texts without hate speech
<span class="citation" data-cites="hate_speech_classifier">(Aluru et
al., 2020)</span>. As hate speech is part of content that is considered
toxic, the classification results are a direct indicator if Formula 1
fandom is toxic or not.</p>
<p>The model is a derivative of the BERT transformer family and can only
work with english texts <span class="citation"
data-cites="hate_speech_classifier">(Aluru et al., 2020)</span>. It has
been trained on a combined dataset from 6 publicly available hate speech
datasets, which include examples from sources like Twitter and
Stormfront. During validation and testing, the model achieved a score of
0.71, with that being the highest score reached over all models tested.
It has been shown, that it performs best in high ressource settings,
where the dataset has to contain more then 256 datapoints. During model
development, Aluru et. al. conducted research into trying to understand
based on which text fragments, the model makes it predictions. This
research suggested, that the model is not heavily influenced by the
presence of certain keywords, it rather looks for the context in which
the words appear in <span class="citation"
data-cites="hate_speech_classifier">(Aluru et al., 2020)</span>. Thus,
verbs like hunt or expel are receiving higher attention values from the
model, then a direct insult. However, the presence of a verb which could
be bad is not enough to lead the model to classify text as hate, only if
a verb is paired with an insult or a direct target or in other words if
the context fits, the model will predict hateful content. As an example,
“Mexicans are f**king great people” will be classified as non-hate even
though it contains the word f**ck. However, “I f**king hate ni**ers!”
will be classified as hate speech. In addition to that, the model can
understand internet obscurtions in insults, such as “f**ck”. It can also
connect text sequences to background knowledge, such that “6 million was
not enough. Next time ovens will be the last of your concerns” will be
classified as hate speech, even though no insult or direct attack was
given <span class="citation" data-cites="hate_speech_classifier">(Aluru
et al., 2020)</span>. The model however is able to understand the
unmentioned target of the sequence in this case jews and that it relates
to the crueltys during the holocaust in germany.</p>
<p>For the actual implementation, the same process as for the sentiment
classifier is reused, as only the model id needs to be changed and model
weights etc. will be loaded automatically.</p>
<div class="sourceCode" id="cb24"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>MODEL <span class="op">=</span> <span class="st">&quot;Hate-speech-CNERG/dehatebert-mono-english&quot;</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(MODEL)</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>config <span class="op">=</span> AutoConfig.from_pretrained(MODEL)</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AutoModelForSequenceClassification.from_pretrained(MODEL)</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>label_list <span class="op">=</span> []</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>score_list <span class="op">=</span> []</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> text <span class="kw">in</span> tqdm(comment_df_for_transformers.text.to_list()):</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>    encoded_input <span class="op">=</span> tokenizer(text, return_tensors<span class="op">=</span><span class="st">&#39;pt&#39;</span>, padding<span class="op">=</span><span class="va">True</span>, truncation<span class="op">=</span><span class="va">True</span>, max_length<span class="op">=</span><span class="dv">514</span>)</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>    output <span class="op">=</span> model(<span class="op">**</span>encoded_input)</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>    scores <span class="op">=</span> output[<span class="dv">0</span>][<span class="dv">0</span>].detach().numpy()</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>    scores <span class="op">=</span> softmax(scores)</span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>    label_list.append(config.id2label[np.argsort(scores)[::<span class="op">-</span><span class="dv">1</span>][<span class="dv">0</span>]])</span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>    score_list.append(<span class="bu">max</span>(scores))</span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>comment_df[<span class="st">&quot;hate_speech_label&quot;</span>] <span class="op">=</span> label_list</span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a>comment_df[<span class="st">&quot;hate_speech_score&quot;</span>] <span class="op">=</span> score_list</span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a>comment_df</span></code></pre></div>
<div class="sourceCode" id="cb25"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>comment_df.to_csv(<span class="st">&quot;datasets/comment_df_hate_speech_transformer.csv&quot;</span>, index<span class="op">=</span><span class="va">False</span>)</span></code></pre></div>
<h2 id="results">Results</h2>
<p>In this chapter the the three research questions:</p>
<ul>
<li>Is Formula 1 Fandom Toxic?</li>
<li>Has toxicity risen over the years?</li>
<li>Is Toxicity in Formula 1 a self-made problem?</li>
</ul>
<p>Will be answered.</p>
<h3 id="is-formula-1-fandom-toxic">Is Formula 1 Fandom Toxic?</h3>
<p>In order to answer this question, the following figure, which shows
the relative counts for indications of toxic behaviour across all
comments in the dataset will be analyzed. With toxic indications beeing
defined as evidence from the dictionary and transformer based analysis,
that point to the possibility that a given comment is toxic. For
example, if the dictionary analysis finds a toxic word from the toxic
words dictionary, this is considered a toxic indication. The term of
toxic indications for relative counts is defined as a binary variable,
that is either true or false. Therefore, it does not matter how much
evidence can be found in a comment in order to compute the relative
counts. It only counts, that evidence has been found and then the
comment is considered to include toxic indications.</p>
<div class="sourceCode" id="cb26"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>comment_df_dictionarys <span class="op">=</span> pd.read_csv(<span class="st">&quot;datasets/comment_df_dicts.csv&quot;</span>)</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>comment_df_hate_speech <span class="op">=</span> pd.read_csv(<span class="st">&quot;datasets/comment_df_hate_speech_transformer.csv&quot;</span>)</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>comment_df_sentiment <span class="op">=</span> pd.read_csv(<span class="st">&quot;datasets/comment_df_sentiment_transformer.csv&quot;</span>)</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>videos: pd.DataFrame <span class="op">=</span> pd.read_pickle(<span class="st">&quot;datasets/video_data.pkl&quot;</span>)</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">len</span>(comment_df_dictionarys))</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">len</span>(comment_df_hate_speech))</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">len</span>(comment_df_sentiment))</span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>comment_df <span class="op">=</span> pd.merge(comment_df_dictionarys, comment_df_hate_speech[[<span class="st">&quot;hate_speech_label&quot;</span>, <span class="st">&quot;hate_speech_score&quot;</span>]], left_index<span class="op">=</span><span class="va">True</span>, right_index<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>comment_df <span class="op">=</span> pd.merge(comment_df, comment_df_sentiment[[<span class="st">&quot;sentiment&quot;</span>, <span class="st">&quot;sentiment_score&quot;</span>]], left_index<span class="op">=</span><span class="va">True</span>, right_index<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a>comment_df</span></code></pre></div>
<div class="sourceCode" id="cb27"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> swifter</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>relative_counts <span class="op">=</span> []</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>columns <span class="op">=</span> [<span class="st">&#39;toxic_word_count&#39;</span>, <span class="st">&#39;deadline_word_count&#39;</span>,</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>       <span class="st">&#39;desperation_word_count&#39;</span>, <span class="st">&#39;fixation_word_count&#39;</span>,</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>       <span class="st">&#39;frustration_word_count&#39;</span>, <span class="st">&#39;god_word_count&#39;</span>, <span class="st">&#39;grievance_word_count&#39;</span>,</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>       <span class="st">&#39;hate_word_count&#39;</span>, <span class="st">&#39;honour_word_count&#39;</span>,</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>       <span class="st">&#39;impostor_word_count&#39;</span>, <span class="st">&#39;jealousy_word_count&#39;</span>,</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>       <span class="st">&#39;murder_word_count&#39;</span>, <span class="st">&#39;paranoia_word_count&#39;</span>,</span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>       <span class="st">&#39;soldier_word_count&#39;</span>, <span class="st">&#39;suicide_word_count&#39;</span>,</span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>       <span class="st">&#39;surveillance_word_count&#39;</span>, <span class="st">&#39;threat_word_count&#39;</span>, <span class="st">&#39;violence_word_count&#39;</span>,</span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a>       <span class="st">&#39;weaponry_word_count&#39;</span>, <span class="st">&#39;ethnic_slurs_word_count&#39;</span>, <span class="st">&#39;hate_speech_label&#39;</span>, <span class="st">&#39;sentiment&#39;</span>]</span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate relative counts</span></span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> column <span class="kw">in</span> columns[:<span class="op">-</span><span class="dv">2</span>]:</span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a>    relative_count <span class="op">=</span> (comment_df[column].swifter.progress_bar(<span class="va">False</span>).<span class="bu">apply</span>(<span class="kw">lambda</span> c: <span class="dv">1</span> <span class="cf">if</span> c <span class="op">&gt;</span> <span class="fl">0.0</span> <span class="cf">else</span> <span class="dv">0</span>).<span class="bu">sum</span>() <span class="op">*</span> <span class="dv">100</span>) <span class="op">/</span> <span class="bu">len</span>(comment_df)</span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a>    relative_counts.append(relative_count)</span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a>relative_counts.append((comment_df[<span class="st">&quot;hate_speech_label&quot;</span>].swifter.progress_bar(<span class="va">False</span>).<span class="bu">apply</span>(<span class="kw">lambda</span> l: <span class="dv">1</span> <span class="cf">if</span> l <span class="op">!=</span> <span class="st">&quot;NON_HATE&quot;</span> <span class="cf">else</span> <span class="dv">0</span>).<span class="bu">sum</span>() <span class="op">*</span> <span class="dv">100</span>) <span class="op">/</span> <span class="bu">len</span>(comment_df))</span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a>relative_counts.append((comment_df[<span class="st">&quot;sentiment&quot;</span>].swifter.progress_bar(<span class="va">False</span>).<span class="bu">apply</span>(<span class="kw">lambda</span> l: <span class="dv">1</span> <span class="cf">if</span> l <span class="op">!=</span> <span class="st">&quot;POSITIVE&quot;</span> <span class="cf">else</span> <span class="dv">0</span>).<span class="bu">sum</span>() <span class="op">*</span> <span class="dv">100</span>) <span class="op">/</span> <span class="bu">len</span>(comment_df))</span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a>relative_counts.append(pd.Series(relative_counts).mean())</span>
<span id="cb27-24"><a href="#cb27-24" aria-hidden="true" tabindex="-1"></a>columns.append(<span class="st">&quot;average_count&quot;</span>)</span>
<span id="cb27-25"><a href="#cb27-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-26"><a href="#cb27-26" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> pd.DataFrame(</span>
<span id="cb27-27"><a href="#cb27-27" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb27-28"><a href="#cb27-28" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;relative_counts&quot;</span>: relative_counts,</span>
<span id="cb27-29"><a href="#cb27-29" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;columns&quot;</span>: columns</span>
<span id="cb27-30"><a href="#cb27-30" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb27-31"><a href="#cb27-31" aria-hidden="true" tabindex="-1"></a>).plot(kind<span class="op">=</span><span class="st">&quot;barh&quot;</span>, x<span class="op">=</span><span class="st">&quot;columns&quot;</span>, y<span class="op">=</span><span class="st">&quot;relative_counts&quot;</span>, figsize<span class="op">=</span>(<span class="dv">15</span>,<span class="dv">12</span>), xlabel<span class="op">=</span><span class="st">&quot;%&quot;</span>, title<span class="op">=</span><span class="st">&quot;Relative counts for indications of toxic behaviour&quot;</span>)</span>
<span id="cb27-32"><a href="#cb27-32" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> ax.bar_label(ax.containers[<span class="dv">0</span>])</span></code></pre></div>
<figure>
<img src="final_files/final_57_0.png" alt="png" />
<figcaption aria-hidden="true">png</figcaption>
</figure>
<p>As shown in the plot, on average across all categorys tested, with
all tests being weighted equally, 21% of all comments show indications
for toxic behaviour. However, if the figure is broken down to the
individual categories, each test paints a different picture. The tests,
that can directly detect parts of toxic behaviour such as hate speech,
ethnic slurs to detect racism and the toxicity dictionary all show low
percentages of comments that actually contain these direct indications.
9% of comments have been flagged as hate speech, 0.1 % of comments
contain ethnic slurs directly and 6% of comments contain toxic words.
Therefore, the fraction of comments with direct evidence for toxic
behaviour is really low, especially in terms of containing racism.
However, the results for the categories of the grievance dictionary are
much higher, ranging from 11% for impostor words and up to 39% for words
in the deadline category. The grievance dictionary showed an especially
high occurence for words regarding, surveillance, god, desperation and
frustration. Which is in the context of the sport not suprising, as
Formula 1 is a highly competitive, popular and dangerous sport which is
government by the FIA, which has been at the center for a lot of
controversy in the last two seasons (2021 &amp; 2022) <span
class="citation" data-cites="richards_fia_2022">(Richards, 2022)</span>.
Therefore, the main talking points in Formula 1 at the moment are the
FIA, teams bending rules, announcements, team errors and recent crashes
of drivers. Because of that, it is not unsurprising that surveillance,
god, desperation and frustration are the categories with the highest
percentages, as they are a natural and direct consequence of the sports
characteristics. All other occurences for the other categorys are
ranging between 10% to 20%, which is not an inconsiderable amount, if
the topics of some categorys are taken into consideration. Almost 20% of
comments show indications for suicide, murder, threat, and violence,
weaponry and hate. This is not an inconsiderable amount, it means that
on average every 5th comment contains life threatening and hateful
content. Also almost 60% of comments show a negative sentiment. Even
though this metric is not representing toxicity directy, it clearly
shows, that Formula 1 fandom is not in a positive frame of mind,
regardless of the discussion topic. In summary, every 5th comment shows
clear indications for toxic content, with 60% percent of comments being
negative. Therefore, one could make the assumption that Formula 1 fandom
is indeed toxic, especially because of the frequency that one can
observe comments with toxic behaviour. However, the situation is not as
bad on social media as reports might suggest. The overall current
negativity in Formula 1 fandom is amplifying the perception of toxicity
in Formula 1 fandom as most people connect toxic behaviour not just with
racism, misogyny and hate speech but rather with overall negative
behaviour <span class="citation" data-cites="toxic_fandom">(<span>“What
<span>Is</span> <span>Toxic</span> <span>Fandom</span>?”</span>
n.d.)</span>. Therefore, most people will consider current Formula 1
fandom as toxic, especially paired with recent reports of toxic and
abusive behaviour during events and online <span class="citation"
data-cites="f1_drivers_addressing_toxic_fans">(<em>3 Times
<span>F1</span> Drivers Addressed Toxic Fan Behavior</em>, n.d.)</span>
<span class="citation" data-cites="woodhouse_scary_2022">(Woodhouse,
2022)</span>.</p>
<h3 id="has-toxicity-risen-over-the-years">Has toxicity risen over the
years?</h3>
<p>In order to conclude if Formula 1 fandom got more toxic in recent
years, the number of toxic indications per year will be analyzed.</p>
<div class="sourceCode" id="cb28"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>comment_df[<span class="st">&quot;contains_toxic_indications&quot;</span>] <span class="op">=</span> comment_df[[<span class="st">&quot;sentiment&quot;</span>, <span class="st">&quot;hate_speech_label&quot;</span>]].swifter.progress_bar(<span class="va">False</span>).<span class="bu">apply</span>(<span class="kw">lambda</span> r: <span class="dv">1</span> <span class="cf">if</span> r.sentiment <span class="op">!=</span> <span class="st">&quot;POSITIVE&quot;</span> <span class="kw">or</span> r.hate_speech_label <span class="op">!=</span> <span class="st">&quot;NON_HATE&quot;</span> <span class="cf">else</span> <span class="dv">0</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>grouped <span class="op">=</span> comment_df[[<span class="st">&quot;video_id&quot;</span>, <span class="st">&quot;contains_toxic_indications&quot;</span>]].groupby(by<span class="op">=</span><span class="st">&quot;video_id&quot;</span>).<span class="bu">sum</span>()</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>grouped.index <span class="op">=</span> grouped.index.astype(<span class="bu">str</span>)</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>videos.video_id <span class="op">=</span> videos.video_id.astype(<span class="bu">str</span>)</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>videos <span class="op">=</span> pd.merge(videos, grouped, left_on<span class="op">=</span><span class="st">&quot;video_id&quot;</span>, right_index<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>videos.published_at <span class="op">=</span> pd.to_datetime(videos.published_at)</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>videos.info()</span></code></pre></div>
<div class="sourceCode" id="cb29"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>videos.groupby(by<span class="op">=</span>videos.published_at.dt.year).<span class="bu">sum</span>().plot(kind<span class="op">=</span><span class="st">&#39;bar&#39;</span>, figsize<span class="op">=</span>(<span class="dv">8</span>,<span class="dv">5</span>))</span></code></pre></div>
<pre><code>&lt;AxesSubplot: xlabel=&#39;published_at&#39;&gt;</code></pre>
<figure>
<img src="final_files/final_61_1.png" alt="png" />
<figcaption aria-hidden="true">png</figcaption>
</figure>
<p>As shwon in the Figure above, the overall number of comments with
toxic indications have risen drastically over the years. Jumping from
around 3.500 comments with toxic indications to around 18.000 comments
with toxic indications. This marks an increase of over 500%, or in other
words, the amount of comments with toxic ambivalences have
<strong>quintupled</strong>. This figure becomes even more alarming if
the data in the following figure is taken into consideration as
well.</p>
<div class="sourceCode" id="cb31"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">5</span>))</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>videos.comment_count <span class="op">=</span> videos.comment_count.astype(<span class="bu">int</span>)</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>videos.like_count <span class="op">=</span> videos.like_count.astype(<span class="bu">int</span>)</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>ax2 <span class="op">=</span> ax.twinx()</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>videos[[<span class="st">&quot;published_at&quot;</span>, <span class="st">&quot;comment_count&quot;</span>]].groupby(by<span class="op">=</span>[videos.published_at.dt.year ,videos.published_at.dt.month]).mean().plot(ax<span class="op">=</span>ax, style<span class="op">=</span><span class="st">&#39;.-&#39;</span>, xlabel<span class="op">=</span><span class="st">&quot;published at&quot;</span>, ylabel<span class="op">=</span><span class="st">&quot;average total comment count&quot;</span>)</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>videos[[<span class="st">&quot;published_at&quot;</span>, <span class="st">&quot;like_count&quot;</span>]].groupby(by<span class="op">=</span>[videos.published_at.dt.year ,videos.published_at.dt.month]).mean().plot(ax<span class="op">=</span>ax2, style<span class="op">=</span><span class="st">&#39;.-&#39;</span>, xlabel<span class="op">=</span><span class="st">&quot;published at&quot;</span>, c<span class="op">=</span><span class="st">&quot;darkgreen&quot;</span>, ylabel<span class="op">=</span><span class="st">&quot;average total like count&quot;</span>)</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.arange(<span class="dv">32</span>)</span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> videos.groupby(by<span class="op">=</span>[videos.published_at.dt.year ,videos.published_at.dt.month]).mean().comment_count.to_list()</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> np.polyfit(x,y,<span class="dv">2</span>)</span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> np.poly1d(z)</span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>ax.plot(x, p(x), linestyle<span class="op">=</span><span class="st">&quot;dashed&quot;</span>, label<span class="op">=</span><span class="st">&quot;trend&quot;</span>)</span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a>ax.axvline(<span class="dv">0</span>, color<span class="op">=</span><span class="st">&quot;red&quot;</span>, label<span class="op">=</span><span class="st">&quot;2020 season&quot;</span>)</span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a>ax.axvline(<span class="dv">10</span>, color<span class="op">=</span><span class="st">&quot;green&quot;</span>, label<span class="op">=</span><span class="st">&quot;2021 season&quot;</span>)</span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a>ax.axvline(<span class="dv">22</span>, color<span class="op">=</span><span class="st">&quot;orange&quot;</span>, label<span class="op">=</span><span class="st">&quot;2022 season&quot;</span>)</span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a>lns <span class="op">=</span> ax.get_lines() <span class="op">+</span> ax2.get_lines()</span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a>ax.legend(ax.get_lines() <span class="op">+</span> ax2.get_lines(), [l.get_label() <span class="cf">for</span> l <span class="kw">in</span> lns])</span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a>ax.axvline(<span class="dv">8</span>, color<span class="op">=</span><span class="st">&quot;red&quot;</span>)</span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a>ax.axvline(<span class="dv">19</span>, color<span class="op">=</span><span class="st">&quot;green&quot;</span>)</span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a>ax.axvline(<span class="dv">30</span>, color<span class="op">=</span><span class="st">&quot;orange&quot;</span>)</span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a>ax2.get_legend().remove()</span></code></pre></div>
<figure>
<img src="final_files/final_63_0.png" alt="png" />
<figcaption aria-hidden="true">png</figcaption>
</figure>
<p>The figure shows the amount of comments and likes each video got over
the past 2 years. The comment count and like count together, can be seen
as an indicator about how much attention and interaction each video got.
As shown in the figure by the blue and green line, the curve of the
amount of comments and likes are almost identical, with the yellow trend
line showing a clear negative or decreasing trend, that is becoming
shallower towards the end. With the data about the amount of toxic
indications in comments per year, this data paints an alarming picture,
as toxicity in comments quintupled, while the overall interactions and
attentions each video got has been declining to around 21% of its level
from the beginning of the 2020 season. This indicates, that the relative
amount of toxicity in Formula 1 Fandom could be even higher then
displayed through the dataset. In summary then, Toxicity in Formula 1
Fandom has been rising, especially between 2021 and 2022, with the trend
line predicting an increase for the future as well, as depicted by the
following figure.</p>
<div class="sourceCode" id="cb32"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> videos[[<span class="st">&quot;published_at&quot;</span>, <span class="st">&quot;contains_toxic_indications&quot;</span>]].groupby(by<span class="op">=</span>[videos.published_at.dt.year ,videos.published_at.dt.month]).<span class="bu">sum</span>().plot(style<span class="op">=</span><span class="st">&#39;.-&#39;</span>, figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">5</span>), xlabel<span class="op">=</span><span class="st">&quot;published at&quot;</span>)</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.arange(<span class="dv">32</span>)</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> videos.groupby(by<span class="op">=</span>[videos.published_at.dt.year ,videos.published_at.dt.month]).<span class="bu">sum</span>().contains_toxic_indications.to_list()</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> np.polyfit(x,y,<span class="dv">1</span>)</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> np.poly1d(z)</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>ax.plot(x, p(x), linestyle<span class="op">=</span><span class="st">&quot;dashed&quot;</span>, label<span class="op">=</span><span class="st">&quot;trend&quot;</span>)</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>ax.axvline(<span class="dv">0</span>, color<span class="op">=</span><span class="st">&quot;red&quot;</span>, label<span class="op">=</span><span class="st">&quot;2020 season&quot;</span>)</span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a>ax.axvline(<span class="dv">8</span>, color<span class="op">=</span><span class="st">&quot;red&quot;</span>)</span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>ax.axvline(<span class="dv">10</span>, color<span class="op">=</span><span class="st">&quot;green&quot;</span>, label<span class="op">=</span><span class="st">&quot;2021 season&quot;</span>)</span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a>ax.axvline(<span class="dv">19</span>, color<span class="op">=</span><span class="st">&quot;green&quot;</span>)</span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a>ax.axvline(<span class="dv">22</span>, color<span class="op">=</span><span class="st">&quot;orange&quot;</span>, label<span class="op">=</span><span class="st">&quot;2022 season&quot;</span>)</span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a>ax.axvline(<span class="dv">30</span>, color<span class="op">=</span><span class="st">&quot;orange&quot;</span>)</span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a>ax.legend()</span></code></pre></div>
<pre><code>&lt;matplotlib.legend.Legend at 0x328fec5e0&gt;</code></pre>
<figure>
<img src="final_files/final_65_1.png" alt="png" />
<figcaption aria-hidden="true">png</figcaption>
</figure>
<div class="sourceCode" id="cb34"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>grouped.mean()</span></code></pre></div>
<pre><code>contains_toxic_indications    52.708696
dtype: float64</code></pre>
<h3 id="is-toxicity-a-self-made-problem">Is toxicity a self-made
problem?</h3>
<p>Whether toxicity is a self-made problem of Formula 1 is hard to
reason about. However, Formula 1 is a public company, that makes money
based on sponsorships, advertising and viewing numbers <span
class="citation"
data-cites="formula_1_limited_company_profile">(<em>Formula
<span>One</span> <span>World</span> <span>Championship</span>
<span>Ltd</span> - <span>Company</span> <span>Profile</span> and
<span>News</span> - <span>Bloomberg</span> <span>Markets</span></em>,
n.d.)</span>. Therefore, it is essential for Formula 1 to keep the
amount of entertainment and interactions high, as well as having an
increasingly large fan base or fandom. However, as shown in the
following figure <span class="citation"
data-cites="noauthor_tv_nodate">(Statista, n.d.)</span>, the amount of
viewers were steadily decreasing from 2011 to 2017. During this time
Formula 1 entered a new era of technical regulations, which has been
called the hybrid era, which has been dominated by Mercedes AMG Petronas
for seven consecutive years.</p>
<figure>
<img src="images/F1_viewers.png" alt="F1 TV viewing figure" />
<figcaption aria-hidden="true">F1 TV viewing figure</figcaption>
</figure>
<p>Which lead many people to leave the sport, as a lot of the
entertainment factor was missing. Which lead to Formula hitting an all
time low in 2017. As a result to that worrying development, in 2017
Formula 1 signed an aggressive exclusivity deal with Netflix for an
exclusive documentary reality show called “Drive to Survive” which
should portray the amount of controversy, excitement and high class
racing that Formula 1 is, while simultaneously showing off exclusive
behind the scenes content and making Formula 1 more accessible by the
average Netflix viewer <span class="citation"
data-cites="goodman_why_2022">(Goodman, 2022)</span>. The first season
that aired on Netflix was an instant hit and lead to a surge in Formula
1s popularity across the globe, as reflected in the data showed in the
figure above. The series was especially successfull in the USA, as
Formula 1 never really got a foothold in the USA in the past, the series
lead to F1s popularity skyrocketing. ESPNs F1 viewing figures increaed
by 170% (from approx. 550.000 to 935.000) <span class="citation"
data-cites="goodman_why_2022">(Goodman, 2022)</span> and the 2022
American Grand Prix breaking the record for the highest amount of
spectators ever recorded <span class="citation"
data-cites="noauthor_formula_nodate">(F1Destinations, n.d.)</span>.
However, as the seasons progressed, the series became more and more a
reality show about Formula 1 and the documentary aspect moved more and
more in the background. As a result, many controversies, rivalrys and
aspects of the sport are now artificially amplified, not fully narrated
or told in a queer and distorded way and sometimes it goes as far as
artificially creating rivalries where there never has been any <span
class="citation" data-cites="milburn_heres_2020">(Milburn, 2020)</span>.
Which lead to a rivalry between old Formula 1 fans and the new ones
attracted by drive to survive but also between Fans of different teams
and drivers. Also the term “DTS fan” which is an abbreviation for a fan
that is following F1 because of Drive to Survive becoming a common
insult in Formula 1 fandom for fans making assumptions that are not true
or just don’t fit into an older fans perspective of the sport. In
addition to that, decisions and actions of the governing body of Formula
1, the FIA became more and more questionable since 2021 <span
class="citation" data-cites="richards_fia_2022">(Richards, 2022)</span>,
with a prime example, that is still discussed a lot today, being the
championship decider in 2021. During this race, a late safety car lead
to a lot of controversy, as the race director “interpreted” the a rule
which stated that “any” lapped cars must over take the safety car to
unlap themself and allow for a clean restart. However, in order to allow
for one lap of thrilling and exciting racing, the race director only
allowed the cars between the championship rivals to unlap themself and
restarted the race afterwards. This allowed Max Verstappen to overtake
Lewis Hamilton and secure his first ever drivers championship. Many
similar incidents and inconsistencies from the governing body in regards
to race decisions followed <span class="citation"
data-cites="noauthor_fia_nodate">(Race, n.d.)</span>. This lead not only
to an increasing rivalry between fans of different teams and drivers,
but also to a lot of fans attacking the FIA. In summary then, is the
Toxicity in Formula 1 Fandom a self-made problem? Well, one could
certainly argue that it is. Formula 1 as a corporation needs the amount
of entertainment and attention, controversies create. The same applies
to Drive to Survive. Formula 1 needs Drive to Survive to draw more
people into the sport and to reach its key performance indicators. The
toxicity in Formula 1 fandom is just a side effect of the strategies
Formula 1 is following. In addition to that, Formula 1 is becoming more
and more political with campaigns against racism, or for environmentally
friendly programs, which adds another friction point between fans if
they don’t agree with portrayed political views.</p>
<h2 id="result-validity">Result Validity</h2>
<p>The results are only valid for the given dataset, which has been
shown to have its limitations, as presented earlier. The transformer
predictions have an average of 88% - 95% certainty. Therefore, the
likelihood of the predictions being correct is quite high.</p>
<div class="sourceCode" id="cb36"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>comment_df.sentiment_score.mean()</span></code></pre></div>
<pre><code>0.9551236870340416</code></pre>
<div class="sourceCode" id="cb38"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>comment_df.hate_speech_score.mean()</span></code></pre></div>
<pre><code>0.8822260307092021</code></pre>
<p>However, the dictionary results contain a lot of False positives, as
words of the dictionary are overlapping with Formula 1 domain language.
For example mick is a word of the toxic words dictionary but it is also
the name of a driver for the HAAS Formula 1 team. As a consequence,
every comment that is about Mick Schumacher is automatically flagged as
toxic. The same applies for some of the categories of the grievance
dictionary. As explained in the result section, crashes and dangerous
incidents are part of the sport. Therefore verbalizations about god, or
death are really common as they can also express relief that a driver
didn’t die.</p>
<p>In addition to that, I, as the authot of this report, certainly have
biased opinions on some of the discussed topics myself. As I am part of
Formula 1 fandom and a Redbull Racing supporter. Because of that, an
unbiased review of comment classification with toxic indications by
unbiased annotators should be conducted in the future.</p>
<h2 id="conclusion">Conclusion</h2>
<p>In this thesis, the toxicity in Formula 1 has been analysed based on
a custom dataset of 40200 comments from 500 videos of the official
Formula 1 Youtube channel. First the fundamentals about what fandom and
toxic behaviour is have been layed out. After that, the dataset creation
process has been presented. Then the three dictionarys used, along with
the dictionary analysis method have been shown. In addition to that, two
transformer classifiers have been applied to the dataset in order to
detect comment sentiment and hate speech in comments. The results
showed, that on average every 5th comment in the dataset contained toxic
indications which are often connected to life threatening and hateful
behaviour, which concluded the first research question, as Formula 1
Fandom was deemed to be toxic. Following this discussion, it has been
analyzed if Toxicity in Formula 1 Fandom has risen over the years. The
results showed, that the amount of comments with toxic indications
quintupled from 2020 to 2022, while simultaneously the videos were
receiving less interactions. This marks a dark future for Formula 1 and
Formula 1 Fandom, as the trend curves are both predicting a similar
picture for the future. Last but not least, it has been discussed if
toxicity in Formula 1 Fandom is a self-made problem of Formula 1. It has
been argued, that indeed Formula 1s strategy to fan and economic growth,
paired with the increasing amount of political topics addressed by
Formula 1 are certainly playing a role in the rise of toxicity and may
well be one of the reason. Therefore it was concluded, that yes toxicity
is (at least partially) a self-made problem.</p>
<h2 id="bibliography">Bibliography</h2>
<!--


```python
import os
os.system("jupyter nbconvert --to markdown final.ipynb")
os.system("pandoc -s final.md -t html -o final.html --citeproc --bibliography=refs.bib --csl=apa.csl")
os.system("pandoc -s final.md -t pdf -o final.pdf --citeproc --bibliography=refs.bib --csl=apa.csl")
```

    [NbConvertApp] Converting notebook final.ipynb to markdown
    [NbConvertApp] Support files will be in final_files/
    [NbConvertApp] Making directory final_files
    [NbConvertApp] Making directory final_files
    [NbConvertApp] Making directory final_files
    [NbConvertApp] Making directory final_files
    [NbConvertApp] Making directory final_files
    [NbConvertApp] Making directory final_files
    [NbConvertApp] Writing 57026 bytes to final.md
    [WARNING] This document format requires a nonempty <title> element.
      Defaulting to 'final' as the title.
      To specify a title, use 'title' in metadata or --metadata title="...".





    0



-->
<div id="refs" class="references csl-bib-body hanging-indent"
data-line-spacing="2" role="doc-bibliography">
<div id="ref-f1_drivers_addressing_toxic_fans" class="csl-entry"
role="doc-biblioentry">
<em>3 times <span>F1</span> drivers addressed toxic fan behavior</em>.
(n.d.). Retrieved January 7, 2023, from <a
href="https://www.sportskeeda.com/f1/3-times-f1-drivers-addressed-toxic-fan-behavior">https://www.sportskeeda.com/f1/3-times-f1-drivers-addressed-toxic-fan-behavior</a>
</div>
<div id="ref-hate_speech_classifier" class="csl-entry"
role="doc-biblioentry">
Aluru, S. S., Mathew, B., Saha, P., &amp; Mukherjee, A. (2020). <em>Deep
<span>Learning</span> <span>Models</span> for <span>Multilingual</span>
<span>Hate</span> <span>Speech</span> <span>Detection</span></em>.
arXiv. <a
href="https://doi.org/10.48550/arXiv.2004.06465">https://doi.org/10.48550/arXiv.2004.06465</a>
</div>
<div id="ref-arouh_toxic_2020" class="csl-entry" role="doc-biblioentry">
Arouh, M. (2020). Toxic <span>Fans</span>: <span>Distinctions</span> and
<span>Ambivalence</span>. <em>Ex-Centric Narratives: Journal of
Anglophone Literature, Culture and Media</em>, <em>4</em>, 67–82. <a
href="https://doi.org/10.26262/exna.v0i4.7917">https://doi.org/10.26262/exna.v0i4.7917</a>
</div>
<div id="ref-tweet_sentiment_classifier" class="csl-entry"
role="doc-biblioentry">
Barbieri, F., Camacho-Collados, J., Neves, L., &amp; Espinosa-Anke, L.
(2020). <em><span>TweetEval</span>: <span>Unified</span>
<span>Benchmark</span> and <span>Comparative</span>
<span>Evaluation</span> for <span>Tweet</span>
<span>Classification</span></em>. arXiv. <a
href="http://arxiv.org/abs/2010.12421">http://arxiv.org/abs/2010.12421</a>
</div>
<div id="ref-noauthor_formula_nodate" class="csl-entry"
role="doc-biblioentry">
F1Destinations. (n.d.). <em>Formula 1 attendance exceeds 5 million in
2022 - <span>F1Destinations</span>.com</em>. Retrieved January 14, 2023,
from <a
href="https://f1destinations.com/formula-1-attendance-exceeds-5-million-in-2022/">https://f1destinations.com/formula-1-attendance-exceeds-5-million-in-2022/</a>
</div>
<div id="ref-formula_1_2023" class="csl-entry" role="doc-biblioentry">
Formula <span>One</span>. (2023). In <em>Wikipedia</em>. <a
href="https://en.wikipedia.org/w/index.php?title=Formula_One&amp;oldid=1132488425">https://en.wikipedia.org/w/index.php?title=Formula_One&amp;oldid=1132488425</a>
</div>
<div id="ref-formula_1_limited_company_profile" class="csl-entry"
role="doc-biblioentry">
<em>Formula <span>One</span> <span>World</span>
<span>Championship</span> <span>Ltd</span> - <span>Company</span>
<span>Profile</span> and <span>News</span> - <span>Bloomberg</span>
<span>Markets</span></em>. (n.d.). Retrieved January 9, 2023, from <a
href="https://www.bloomberg.com/profile/company/1935454Z:LN">https://www.bloomberg.com/profile/company/1935454Z:LN</a>
</div>
<div id="ref-goodman_why_2022" class="csl-entry" role="doc-biblioentry">
Goodman, K. (2022). <em>Why <span>Formula</span> 1 is <span>So</span>
<span>Popular</span> <span>Right</span> <span>Now</span> <span></span>
<span>Weird</span> <span>Marketing</span></em>. <a
href="https://weirdmarketingtales.com/why-formula-1-is-so-popular-right-now/">https://weirdmarketingtales.com/why-formula-1-is-so-popular-right-now/</a>
</div>
<div id="ref-distilbert_sentiment" class="csl-entry"
role="doc-biblioentry">
HF Canonical Model Maintainers. (2022).
<em>Distilbert-base-uncased-finetuned-sst-2-english (revision
bfdd146)</em>. Hugging Face. <a
href="https://doi.org/ 10.57967/hf/0181 ">https://doi.org/
10.57967/hf/0181 </a>
</div>
<div id="ref-ethnic_slurs" class="csl-entry" role="doc-biblioentry">
List of ethnic slurs. (2023). In <em>Wikipedia</em>. <a
href="https://en.wikipedia.org/w/index.php?title=List_of_ethnic_slurs&amp;oldid=1132041045">https://en.wikipedia.org/w/index.php?title=List_of_ethnic_slurs&amp;oldid=1132041045</a>
</div>
<div id="ref-about_f1" class="csl-entry" role="doc-biblioentry">
Lowrey, T. (2019). <em>About <span>F1</span> <span></span>
<span>Formula</span> <span>One</span> <span>World</span>
<span>Championship</span> <span>Limited</span></em>. <a
href="https://corp.formula1.com/about-f1/">https://corp.formula1.com/about-f1/</a>
</div>
<div id="ref-milburn_heres_2020" class="csl-entry"
role="doc-biblioentry">
Milburn, J. (2020). Here’s <span>What</span> <span>Fake</span>
<span>And</span> <span>Real</span> <span>About</span> <span>F1</span>
<span>Drive</span> <span>To</span> <span>Survive</span> <span>On</span>
<span>Netflix</span>. In <em>HotCars</em>. <a
href="https://www.hotcars.com/heres-whats-fake-about-netflixs-drive-to-survive/">https://www.hotcars.com/heres-whats-fake-about-netflixs-drive-to-survive/</a>
</div>
<div id="ref-orthrus-lexicon_orthrus_2022" class="csl-entry"
role="doc-biblioentry">
Orthrus-Lexicon. (2022). <em>Orthrus <span>Toxic</span>
<span>Dictionary</span> implementation</em>. <a
href="https://github.com/Orthrus-Lexicon/Toxic">https://github.com/Orthrus-Lexicon/Toxic</a>
</div>
<div id="ref-proctor_editors_2018" class="csl-entry"
role="doc-biblioentry">
Proctor, W., &amp; Kies, B. (2018). <em>Editors’
<span>Introduction</span>: <span>On</span> toxic fan practices and the
new culture wars</em>. <em>15</em>(1).
</div>
<div id="ref-noauthor_fia_nodate" class="csl-entry"
role="doc-biblioentry">
Race, T. (n.d.). <em><span>FIA</span> ’launches thorough review’ after
<span>Japan</span> <span>GP</span> truck controversy - <span>The</span>
<span>Race</span></em>. Retrieved January 14, 2023, from <a
href="https://the-race.com/formula-1/fia-launches-thorough-review-after-japan-gp-truck-controversy/">https://the-race.com/formula-1/fia-launches-thorough-review-after-japan-gp-truck-controversy/</a>
</div>
<div id="ref-richards_fia_2022" class="csl-entry"
role="doc-biblioentry">
Richards, G. (2022). <span>FIA</span> report blames <span>“human
error”</span> for <span>Abu</span> <span>Dhabi</span> <span>GP</span>
controversy but result stands. <em>The Guardian</em>. <a
href="https://www.theguardian.com/sport/2022/mar/19/fia-report-blames-human-error-for-abu-dhabi-gp-controversy-but-result-stands">https://www.theguardian.com/sport/2022/mar/19/fia-report-blames-human-error-for-abu-dhabi-gp-controversy-but-result-stands</a>
</div>
<div id="ref-sst-2" class="csl-entry" role="doc-biblioentry">
Socher, R., Perelygin, A., Wu, J., Chuang, J., Manning, C. D., Ng, A.,
&amp; Potts, C. (2013). Recursive deep models for semantic
compositionality over a sentiment treebank. <em>Proceedings of the 2013
Conference on Empirical Methods in Natural Language Processing</em>,
1631–1642. <a
href="https://www.aclweb.org/anthology/D13-1170">https://www.aclweb.org/anthology/D13-1170</a>
</div>
<div id="ref-noauthor_tv_nodate" class="csl-entry"
role="doc-biblioentry">
Statista. (n.d.). <span>TV</span> viewers of <span>Formula</span>
<span>One</span> (<span>F1</span>) worldwide 2021. In <em>Statista</em>.
Retrieved January 13, 2023, from <a
href="https://www.statista.com/statistics/480129/cable-or-broadcast-tv-networks-formula-one-f1-racing-watched-within-the-last-12-months-usa/">https://www.statista.com/statistics/480129/cable-or-broadcast-tv-networks-formula-one-f1-racing-watched-within-the-last-12-months-usa/</a>
</div>
<div id="ref-vaswani_attention_2017" class="csl-entry"
role="doc-biblioentry">
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez,
A. N., Kaiser, L., &amp; Polosukhin, I. (2017). <em>Attention
<span>Is</span> <span>All</span> <span>You</span>
<span>Need</span></em>. arXiv. <a
href="https://doi.org/10.48550/arXiv.1706.03762">https://doi.org/10.48550/arXiv.1706.03762</a>
</div>
<div id="ref-van_der_vegt_grievance_2021" class="csl-entry"
role="doc-biblioentry">
Vegt, I. van der, Mozes, M., Kleinberg, B., &amp; Gill, P. (2021). The
<span>Grievance</span> <span>Dictionary</span>:
<span>Understanding</span> threatening language use. <em>Behavior
Research Methods</em>, <em>53</em>(5), 2105–2119. <a
href="https://doi.org/10.3758/s13428-021-01536-2">https://doi.org/10.3758/s13428-021-01536-2</a>
</div>
<div id="ref-wang2019glue" class="csl-entry" role="doc-biblioentry">
Wang, A., Singh, A., Michael, J., Hill, F., Levy, O., &amp; Bowman, S.
R. (2019). <em><span>GLUE</span>: A multi-task benchmark and analysis
platform for natural language understanding</em>.
</div>
<div id="ref-toxic_fandom" class="csl-entry" role="doc-biblioentry">
What <span>Is</span> <span>Toxic</span> <span>Fandom</span>? (n.d.). In
<em>Verywell Mind</em>. Retrieved January 7, 2023, from <a
href="https://www.verywellmind.com/what-is-toxic-fandom-5214499">https://www.verywellmind.com/what-is-toxic-fandom-5214499</a>
</div>
<div id="ref-woodhouse_scary_2022" class="csl-entry"
role="doc-biblioentry">
Woodhouse, J. (2022). <span>“<span>Scary</span>”</span> how toxic
<span>Formula</span> 1 community became during 2021. In
<em>PlanetF1</em>. <a
href="https://www.planetf1.com/news/toxic-formula-1-community-2021/">https://www.planetf1.com/news/toxic-formula-1-community-2021/</a>
</div>
</div>
</body>
</html>
